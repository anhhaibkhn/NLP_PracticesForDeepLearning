{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\nTagged sentences:  3914\nTagged words: 100676\n"
    }
   ],
   "source": [
    "#Activity 2: Building and Training POS Tagger. Using CRF ( Conditional Random Field)\n",
    "import nltk\n",
    " \n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    " \n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction function:\n",
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2935\n979\n[{'word': 'Pierre', 'is_first': True, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'P', 'prefix-2': 'Pi', 'prefix-3': 'Pie', 'suffix-1': 'e', 'suffix-2': 're', 'suffix-3': 'rre', 'prev_word': '', 'next_word': 'Vinken', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'Vinken', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'V', 'prefix-2': 'Vi', 'prefix-3': 'Vin', 'suffix-1': 'n', 'suffix-2': 'en', 'suffix-3': 'ken', 'prev_word': 'Pierre', 'next_word': ',', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': ',', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': ',', 'prefix-2': ',', 'prefix-3': ',', 'suffix-1': ',', 'suffix-2': ',', 'suffix-3': ',', 'prev_word': 'Vinken', 'next_word': '61', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': '61', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': '6', 'prefix-2': '61', 'prefix-3': '61', 'suffix-1': '1', 'suffix-2': '61', 'suffix-3': '61', 'prev_word': ',', 'next_word': 'years', 'has_hyphen': False, 'is_numeric': True, 'capitals_inside': False}, {'word': 'years', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'y', 'prefix-2': 'ye', 'prefix-3': 'yea', 'suffix-1': 's', 'suffix-2': 'rs', 'suffix-3': 'ars', 'prev_word': '61', 'next_word': 'old', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'old', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'o', 'prefix-2': 'ol', 'prefix-3': 'old', 'suffix-1': 'd', 'suffix-2': 'ld', 'suffix-3': 'old', 'prev_word': 'years', 'next_word': ',', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': ',', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': ',', 'prefix-2': ',', 'prefix-3': ',', 'suffix-1': ',', 'suffix-2': ',', 'suffix-3': ',', 'prev_word': 'old', 'next_word': 'will', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'will', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'w', 'prefix-2': 'wi', 'prefix-3': 'wil', 'suffix-1': 'l', 'suffix-2': 'll', 'suffix-3': 'ill', 'prev_word': ',', 'next_word': 'join', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'join', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'j', 'prefix-2': 'jo', 'prefix-3': 'joi', 'suffix-1': 'n', 'suffix-2': 'in', 'suffix-3': 'oin', 'prev_word': 'will', 'next_word': 'the', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'the', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 't', 'prefix-2': 'th', 'prefix-3': 'the', 'suffix-1': 'e', 'suffix-2': 'he', 'suffix-3': 'the', 'prev_word': 'join', 'next_word': 'board', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'board', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'b', 'prefix-2': 'bo', 'prefix-3': 'boa', 'suffix-1': 'd', 'suffix-2': 'rd', 'suffix-3': 'ard', 'prev_word': 'the', 'next_word': 'as', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'as', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'a', 'prefix-2': 'as', 'prefix-3': 'as', 'suffix-1': 's', 'suffix-2': 'as', 'suffix-3': 'as', 'prev_word': 'board', 'next_word': 'a', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'a', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'a', 'prefix-2': 'a', 'prefix-3': 'a', 'suffix-1': 'a', 'suffix-2': 'a', 'suffix-3': 'a', 'prev_word': 'as', 'next_word': 'nonexecutive', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'nonexecutive', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'n', 'prefix-2': 'no', 'prefix-3': 'non', 'suffix-1': 'e', 'suffix-2': 've', 'suffix-3': 'ive', 'prev_word': 'a', 'next_word': 'director', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'director', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'd', 'prefix-2': 'di', 'prefix-3': 'dir', 'suffix-1': 'r', 'suffix-2': 'or', 'suffix-3': 'tor', 'prev_word': 'nonexecutive', 'next_word': 'Nov.', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'Nov.', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'N', 'prefix-2': 'No', 'prefix-3': 'Nov', 'suffix-1': '.', 'suffix-2': 'v.', 'suffix-3': 'ov.', 'prev_word': 'director', 'next_word': '29', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': '29', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': '2', 'prefix-2': '29', 'prefix-3': '29', 'suffix-1': '9', 'suffix-2': '29', 'suffix-3': '29', 'prev_word': 'Nov.', 'next_word': '.', 'has_hyphen': False, 'is_numeric': True, 'capitals_inside': False}, {'word': '.', 'is_first': False, 'is_last': True, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': '.', 'prefix-2': '.', 'prefix-3': '.', 'suffix-1': '.', 'suffix-2': '.', 'suffix-3': '.', 'prev_word': '29', 'next_word': '', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}]\n['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n"
    }
   ],
   "source": [
    "#Build our Data Set \n",
    "from nltk.tag.util import untag\n",
    " \n",
    "# Split the dataset for training and testing\n",
    "cutoff = int(.75 * len(tagged_sentences))\n",
    "training_sentences = tagged_sentences[:cutoff]\n",
    "test_sentences = tagged_sentences[cutoff:]\n",
    " \n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    " \n",
    "    for tagged in tagged_sentences:\n",
    "        X.append([features(untag(tagged), index) for index in range(len(tagged))])\n",
    "        y.append([tag for _, tag in tagged])\n",
    " \n",
    "    return X, y\n",
    " \n",
    "X_train, y_train = transform_to_dataset(training_sentences)\n",
    "X_test, y_test = transform_to_dataset(test_sentences)\n",
    " \n",
    "print(len(X_train))     \n",
    "print(len(X_test))         \n",
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('I', 'PRP'), ('am', 'VBP'), ('ZORO', 'NNP'), ('!', '.')]\n"
    }
   ],
   "source": [
    "# Notice how each row in the dataset is a sequence, not a single word. CRFs learn sequences.\n",
    "# install the CRF library using: pip install sklearn-crfsuite\n",
    "from sklearn_crfsuite import CRF\n",
    " \n",
    "model = CRF()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions using our model:\n",
    "sentence = ['I', 'am', 'ZORO','!']\n",
    " \n",
    "def pos_tag(sentence):\n",
    "    sentence_features = [features(sentence, index) for index in range(len(sentence))]\n",
    "    return list(zip(sentence, model.predict([sentence_features])[0]))\n",
    " \n",
    "print(pos_tag(sentence))  # [('I', 'PRP'), ('am', 'VBP'), ('ZORO', 'NNP'), ('!', '.')]\n",
    " \n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9602683593122289\n"
    }
   ],
   "source": [
    "# Compute the performance of the model \n",
    "from sklearn_crfsuite import metrics\n",
    " \n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.flat_accuracy_score(y_test, y_pred))\n",
    " \n",
    "# 0.9602683593122289 this is higher than DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37464bitchapter2envvenv1f1ec2dfaaea420a90c85d71d2b30854",
   "display_name": "Python 3.7.4 64-bit ('chapter2_env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}