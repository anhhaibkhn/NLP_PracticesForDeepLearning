{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitvirtualenvvenv9acec58b124a4af58980f597288afade",
   "display_name": "Python 3.7.4 64-bit ('virtual_env': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.45930054],\n       [0.97661676],\n       [0.99403442]])"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Understand LSTM gates\n",
    "#1 the forget gate calculation\n",
    "import numpy as np \n",
    "np.random.seed(0) # fix random output\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+ np.exp(-x))\n",
    "\n",
    "# Simulating dummy values for previous state and current input\n",
    "h_prev = np.random.randn(3,1)\n",
    "x = np.random.randn(5,1)\n",
    "\n",
    "# initialize Wf, Uf\n",
    "Wf = np.random.randn(3,5) # n_h = 3, n_x = 5; \n",
    "Uf = np.random.randn(3,3)\n",
    "\n",
    "# forget gate\n",
    "f = sigmoid(np.matmul(Wf,x) + np.matmul(Uf, h_prev))\n",
    "f  # size is [n_h,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.00762368],\n       [0.39184172],\n       [0.17027909]])"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#2. the input gate (i_t)\n",
    "Wi = np.random.randn(3,5) # n_h = 3, n_x = 5\n",
    "Ui = np.random.randn(3,3) # n_h = 3\n",
    "\n",
    "i = sigmoid( np.matmul(Wi,x) + np.matmul(Ui, h_prev))\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 0.51233992],\n       [-0.67747899],\n       [-0.99555958]])"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#3. The candidate cell state\n",
    "Wc = np.random.randn(3,5)\n",
    "Uc = np.random.randn(3,3)\n",
    "\n",
    "C_candidate = np.tanh(np.matmul(Wc,x)+np.matmul(Uc,h_prev))\n",
    "C_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-0.70169163],\n       [ 1.1879875 ],\n       [ 1.71505613]])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#4. Cell state Update \n",
    "c_prev = np.random.randn(3,1)\n",
    "c_new = np.multiply(f, c_prev) + np.multiply(i,C_candidate)\n",
    "c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 0.58782959],\n       [-0.82993761],\n       [ 0.74022281]])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#5. Ouput gate  and Current Activation \n",
    "# output gate o\n",
    "Wo = np.random.randn(3,5)\n",
    "Uo = np.random.randn(3,3)\n",
    "o = np.tanh(np.matmul(Wo, x) + np.matmul(Uo, h_prev))\n",
    "o\n",
    "\n",
    "h_new = np.multiply(o, np.tanh(c_new))\n",
    "h_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5572"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "#### Exercise 27. LSTM model to classify Email as Spam or not Spam #####\n",
    "#1. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GRU, LSTM, Dense, Embedding\n",
    "\n",
    "from keras. preprocessing.text import Tokenizer\n",
    "\n",
    "#Read file \n",
    "df = pd.read_csv(\"spam.csv\",encoding=\"latin\")\n",
    "# df.head()\n",
    "#2 Only need Text and Label\n",
    "df = df[[\"v1\",\"v2\"]]\n",
    "# df.head()\n",
    "#3. Chec label distribution \n",
    "df[\"v1\"].value_counts()\n",
    "\n",
    "#4. Map label distriution to 0/1 so that it can be fed to classifier \n",
    "label_map = {\"ham\":0, \"spam\":1}\n",
    "X = df[\"v2\"].values\n",
    "y = df[\"v1\"].map(label_map).values # map() => t create label, values() to return the values as nympy.ndarray without getting axes labels\n",
    "\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[12, 10, 5, 66, 36, 1, 20, 1, 79, 63, 10, 95, 32, 5, 8, 11, 1, 5, 65, 7, 14, 36, 95, 32, 67, 63, 1, 66, 33, 32, 57, 45, 11, 11, 11, 33, 32, 2, 1, 12, 33, 51, 11, 7, 97, 51, 1, 33, 32, 2, 36, 12, 1, 33, 32, 8, 66, 45, 1, 33, 32, 5, 12, 66, 33, 32, 45, 1, 98, 17, 2, 20, 11, 9, 5, 18, 5, 1, 33, 32, 12, 66, 33, 32, 45, 1, 44, 7, 44, 33, 32, 5, 57, 33, 31, 7, 12, 5, 65, 95, 9, 36, 10, 1, 55, 2, 4, 33, 99]\n109\n1084\n[12, 10, 5, 66, 36, 1, 20, 1, 79, 63, 10, 95, 32, 5, 8, 11, 1, 5, 65, 7, 14, 36, 95, 32, 67, 63, 1, 66, 33, 32, 57, 45, 11, 11, 11, 33, 32, 2, 1, 12, 33, 51, 11, 7, 97, 51, 1, 33, 32, 2, 36, 12, 1, 33, 32, 8, 66, 45, 1, 33, 32, 5, 12, 66, 33, 32, 45, 1, 98, 17, 2, 20, 11, 9, 5, 18, 5, 1, 33, 32, 12, 66, 33, 32, 45, 1, 44, 7, 44, 33, 32, 5, 57, 33, 31, 7, 12, 5, 65, 95, 9, 36, 10, 1, 55, 2, 4, 33, 99]\n"
    }
   ],
   "source": [
    "#5. restrict the maximum number of tokens to be generated the 100 most frequent words \n",
    "# intialize a Tokenizer to assign an interger value to each word being used in the corpus\n",
    "Max_words = 100 # Max >=6000\n",
    "MyToken = Tokenizer(nb_words = Max_words, lower = True, split=\" \")\n",
    "MyToken.fit_on_texts(X)\n",
    "text_tokenized = MyToken.texts_to_sequences(X) # Only the words in text belongs to top 100 most frequent words get to be assigned an integer. Ex: 1 sequences X[0] has 20 words, only 6 indices in tokenized representation.\n",
    "# # max_len = max([len(i) for i in text_tokenized])\n",
    "# print(max_len)\n",
    "print(max(text_tokenized, key=len))\n",
    "print(len(max(text_tokenized, key=len)))\n",
    "max_pos = text_tokenized.index(max(text_tokenized, key=len))\n",
    "print(max_pos)\n",
    "print(text_tokenized[1084])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 0,  0,  0, ..., 89, 67, 58],\n       [ 0,  0,  0, ...,  0, 46,  6],\n       [ 0,  0,  0, ...,  2,  2, 73],\n       ...,\n       [ 0,  0,  0, ..., 12, 20, 23],\n       [ 0,  0,  0, ...,  2, 12, 47],\n       [ 0,  0,  0, ..., 61,  2, 61]])"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "# Max Sequence Length of 50 words per/sequence, and pad those sequences shorter than this lengh.  \n",
    "Max_len = 50\n",
    "from keras.preprocessing import sequence\n",
    "sequences = sequence.pad_sequences(text_tokenized, maxlen=Max_len)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([33, 32,  5, 12, 66, 33, 32, 45,  1, 98, 17,  2, 20, 11,  9,  5, 18,\n        5,  1, 33, 32, 12, 66, 33, 32, 45,  1, 44,  7, 44, 33, 32,  5, 57,\n       33, 31,  7, 12,  5, 65, 95,  9, 36, 10,  1, 55,  2,  4, 33, 99])"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "sequences[1084] #  this one got truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 50, 20)            2000      \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 64)                21760     \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 23,825\nTrainable params: 23,825\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(Max_words, 20, input_length=Max_len))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 4457 samples, validate on 1115 samples\nEpoch 1/15\n4457/4457 [==============================] - 1s 323us/step - loss: 0.0887 - accuracy: 0.9704 - val_loss: 0.1009 - val_accuracy: 0.9641\nEpoch 2/15\n4457/4457 [==============================] - 1s 313us/step - loss: 0.0870 - accuracy: 0.9726 - val_loss: 0.1061 - val_accuracy: 0.9677\nEpoch 3/15\n4457/4457 [==============================] - 1s 311us/step - loss: 0.0872 - accuracy: 0.9715 - val_loss: 0.1014 - val_accuracy: 0.9650\nEpoch 4/15\n4457/4457 [==============================] - 1s 317us/step - loss: 0.0851 - accuracy: 0.9731 - val_loss: 0.1007 - val_accuracy: 0.9650\nEpoch 5/15\n4457/4457 [==============================] - 1s 302us/step - loss: 0.0832 - accuracy: 0.9735 - val_loss: 0.1010 - val_accuracy: 0.9650\nEpoch 6/15\n4457/4457 [==============================] - 1s 313us/step - loss: 0.0827 - accuracy: 0.9742 - val_loss: 0.1027 - val_accuracy: 0.9695\nEpoch 7/15\n4457/4457 [==============================] - 1s 307us/step - loss: 0.0836 - accuracy: 0.9733 - val_loss: 0.0989 - val_accuracy: 0.9677\nEpoch 8/15\n4457/4457 [==============================] - 1s 307us/step - loss: 0.0804 - accuracy: 0.9755 - val_loss: 0.0999 - val_accuracy: 0.9668\nEpoch 9/15\n4457/4457 [==============================] - 1s 306us/step - loss: 0.0801 - accuracy: 0.9749 - val_loss: 0.0995 - val_accuracy: 0.9695\nEpoch 10/15\n4457/4457 [==============================] - 1s 300us/step - loss: 0.0810 - accuracy: 0.9753 - val_loss: 0.1025 - val_accuracy: 0.9677\nEpoch 11/15\n4457/4457 [==============================] - 1s 304us/step - loss: 0.0801 - accuracy: 0.9740 - val_loss: 0.1020 - val_accuracy: 0.9659\nEpoch 12/15\n4457/4457 [==============================] - 1s 305us/step - loss: 0.0786 - accuracy: 0.9749 - val_loss: 0.1004 - val_accuracy: 0.9704\nEpoch 13/15\n4457/4457 [==============================] - 1s 299us/step - loss: 0.0787 - accuracy: 0.9742 - val_loss: 0.1011 - val_accuracy: 0.9686\nEpoch 14/15\n4457/4457 [==============================] - 1s 303us/step - loss: 0.0763 - accuracy: 0.9767 - val_loss: 0.1006 - val_accuracy: 0.9695\nEpoch 15/15\n4457/4457 [==============================] - 1s 304us/step - loss: 0.0763 - accuracy: 0.9762 - val_loss: 0.1039 - val_accuracy: 0.9677\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x27beb55a7c8>"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "model.fit(sequences,y, batch_size= 128, epochs= 15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.9985812]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "inp_test_seq = \"WINNER! U win a 500 prize reward & free entry to FA cup final tickets! Text FA to 34212 to receive award\"\n",
    "inp_test_seq2 = \"asdfadsfasdf Free entry in 2 a wkly asdfadf comp to win FA asdfadf Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's asdfadsf\"\n",
    "\n",
    "inp_test_seq3 = \"Thanks for your subscription to Ringtone UK your mobile will be charged �5/month Please confirm by replying YES or NO. If you reply NO you will not be charged. Thank you for reading message. Call me back immediately\"\n",
    "test_sequences = MyToken.texts_to_sequences(np.array([inp_test_seq2]))\n",
    "test_sequences_vec = sequence.pad_sequences(test_sequences, maxlen= Max_len)\n",
    "\n",
    "model.predict(test_sequences_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.9985812]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "test_sequences = MyToken.texts_to_sequences(np.array([inp_test_seq2]))\n",
    "test_sequences_vec = sequence.pad_sequences(test_sequences, maxlen= Max_len)\n",
    "model.predict(test_sequences_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_3 (Embedding)      (None, 50, 20)            2000      \n_________________________________________________________________\ngru_1 (GRU)                  (None, 64)                16320     \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 18,385\nTrainable params: 18,385\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Activity 9 Extra :compare with GRU\n",
    "from keras.layers import GRU\n",
    "GRUmodel = Sequential()\n",
    "GRUmodel.add(Embedding(Max_words, 20, input_length=Max_len))\n",
    "GRUmodel.add(GRU(64))\n",
    "GRUmodel.add(Dense(1, activation=\"sigmoid\"))\n",
    "GRUmodel.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "GRUmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 4457 samples, validate on 1115 samples\nEpoch 1/15\n4457/4457 [==============================] - 2s 363us/step - loss: 0.5396 - accuracy: 0.8438 - val_loss: 0.3390 - val_accuracy: 0.8700\nEpoch 2/15\n4457/4457 [==============================] - 1s 278us/step - loss: 0.2841 - accuracy: 0.8746 - val_loss: 0.1869 - val_accuracy: 0.9247\nEpoch 3/15\n4457/4457 [==============================] - 1s 278us/step - loss: 0.1460 - accuracy: 0.9518 - val_loss: 0.1237 - val_accuracy: 0.9596\nEpoch 4/15\n4457/4457 [==============================] - 1s 274us/step - loss: 0.1125 - accuracy: 0.9639 - val_loss: 0.1111 - val_accuracy: 0.9641\nEpoch 5/15\n4457/4457 [==============================] - 1s 275us/step - loss: 0.1018 - accuracy: 0.9654 - val_loss: 0.1032 - val_accuracy: 0.9686\nEpoch 6/15\n4457/4457 [==============================] - 1s 277us/step - loss: 0.1007 - accuracy: 0.9681 - val_loss: 0.1247 - val_accuracy: 0.9578\nEpoch 7/15\n4457/4457 [==============================] - 1s 284us/step - loss: 0.0971 - accuracy: 0.9708 - val_loss: 0.1025 - val_accuracy: 0.9686\nEpoch 8/15\n4457/4457 [==============================] - 1s 277us/step - loss: 0.0909 - accuracy: 0.9715 - val_loss: 0.1086 - val_accuracy: 0.9650\nEpoch 9/15\n4457/4457 [==============================] - 1s 277us/step - loss: 0.0917 - accuracy: 0.9688 - val_loss: 0.1032 - val_accuracy: 0.9668\nEpoch 10/15\n4457/4457 [==============================] - 1s 273us/step - loss: 0.0894 - accuracy: 0.9711 - val_loss: 0.1049 - val_accuracy: 0.9668\nEpoch 11/15\n4457/4457 [==============================] - 1s 277us/step - loss: 0.0879 - accuracy: 0.9731 - val_loss: 0.1065 - val_accuracy: 0.9659\nEpoch 12/15\n4457/4457 [==============================] - 1s 277us/step - loss: 0.0863 - accuracy: 0.9715 - val_loss: 0.1078 - val_accuracy: 0.9650\nEpoch 13/15\n4457/4457 [==============================] - 1s 311us/step - loss: 0.0850 - accuracy: 0.9717 - val_loss: 0.1065 - val_accuracy: 0.9677\nEpoch 14/15\n4457/4457 [==============================] - 1s 303us/step - loss: 0.0864 - accuracy: 0.9715 - val_loss: 0.1053 - val_accuracy: 0.9677\nEpoch 15/15\n4457/4457 [==============================] - 1s 299us/step - loss: 0.0838 - accuracy: 0.9724 - val_loss: 0.1044 - val_accuracy: 0.9677\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x27bebdc4c08>"
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "GRUmodel.fit(sequences,y, batch_size= 128, epochs= 15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.98544204]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "inp_test_seq = \"WINNER! U win a 500 prize reward & free entry to FA cup final tickets! Text FA to 34212 to receive award\"\n",
    "inp_test_seq2 = \"asdfadsfasdf Free entry in 2 a wkly asdfadf comp to win FA asdfadf Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's asdfadsf\"\n",
    "\n",
    "inp_test_seq3 = \"Thanks for your subscription to Ringtone UK your mobile will be charged �5/month Please confirm by replying YES or NO. If you reply NO you will not be charged. Thank you for reading message. Call me back immediately\"\n",
    "test_sequences = MyToken.texts_to_sequences(np.array([inp_test_seq3]))\n",
    "test_sequences_vec = sequence.pad_sequences(test_sequences, maxlen= Max_len)\n",
    "\n",
    "GRUmodel.predict(test_sequences_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_4 (Embedding)      (None, 50, 20)            2000      \n_________________________________________________________________\nsimple_rnn_1 (SimpleRNN)     (None, 64)                5440      \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 7,505\nTrainable params: 7,505\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Activity 9 compare with SimpleRNN\n",
    "from keras.layers import SimpleRNN\n",
    "RNNmodel = Sequential()\n",
    "RNNmodel.add(Embedding(Max_words, 20, input_length=Max_len))\n",
    "RNNmodel.add(SimpleRNN(64))\n",
    "RNNmodel.add(Dense(1, activation=\"sigmoid\"))\n",
    "RNNmodel.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "RNNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 4457 samples, validate on 1115 samples\nEpoch 1/15\n4457/4457 [==============================] - 1s 139us/step - loss: 0.4314 - accuracy: 0.8427 - val_loss: 0.3763 - val_accuracy: 0.8700\nEpoch 2/15\n4457/4457 [==============================] - 0s 83us/step - loss: 0.3738 - accuracy: 0.8649 - val_loss: 0.3096 - val_accuracy: 0.8709\nEpoch 3/15\n4457/4457 [==============================] - 0s 80us/step - loss: 0.2587 - accuracy: 0.9006 - val_loss: 0.1876 - val_accuracy: 0.9300\nEpoch 4/15\n4457/4457 [==============================] - 0s 78us/step - loss: 0.1600 - accuracy: 0.9455 - val_loss: 0.1311 - val_accuracy: 0.9561\nEpoch 5/15\n4457/4457 [==============================] - 0s 95us/step - loss: 0.1231 - accuracy: 0.9567 - val_loss: 0.1120 - val_accuracy: 0.9632\nEpoch 6/15\n4457/4457 [==============================] - 0s 90us/step - loss: 0.1113 - accuracy: 0.9619 - val_loss: 0.1101 - val_accuracy: 0.9632\nEpoch 7/15\n4457/4457 [==============================] - 0s 97us/step - loss: 0.1272 - accuracy: 0.9562 - val_loss: 0.1079 - val_accuracy: 0.9659\nEpoch 8/15\n4457/4457 [==============================] - 0s 83us/step - loss: 0.1027 - accuracy: 0.9670 - val_loss: 0.1025 - val_accuracy: 0.9623\nEpoch 9/15\n4457/4457 [==============================] - 0s 83us/step - loss: 0.0910 - accuracy: 0.9697 - val_loss: 0.1008 - val_accuracy: 0.9641\nEpoch 10/15\n4457/4457 [==============================] - 0s 90us/step - loss: 0.0851 - accuracy: 0.9722 - val_loss: 0.0972 - val_accuracy: 0.9740\nEpoch 11/15\n4457/4457 [==============================] - 0s 80us/step - loss: 0.0796 - accuracy: 0.9762 - val_loss: 0.0953 - val_accuracy: 0.9731\nEpoch 12/15\n4457/4457 [==============================] - 0s 81us/step - loss: 0.0784 - accuracy: 0.9751 - val_loss: 0.0949 - val_accuracy: 0.9749\nEpoch 13/15\n4457/4457 [==============================] - 0s 83us/step - loss: 0.0745 - accuracy: 0.9787 - val_loss: 0.0967 - val_accuracy: 0.9731\nEpoch 14/15\n4457/4457 [==============================] - 0s 82us/step - loss: 0.0747 - accuracy: 0.9778 - val_loss: 0.0979 - val_accuracy: 0.9722\nEpoch 15/15\n4457/4457 [==============================] - 0s 95us/step - loss: 0.0713 - accuracy: 0.9782 - val_loss: 0.0980 - val_accuracy: 0.9704\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x27bea9a73c8>"
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "RNNmodel.fit(sequences,y, batch_size= 128, epochs= 15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.92302144]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "inp_test_seq = \"WINNER! U win a 500 prize reward & free entry to FA cup final tickets! Text FA to 34212 to receive award\"\n",
    "inp_test_seq2 = \"asdfadsfasdf Free entry in 2 a wkly asdfadf comp to win FA asdfadf Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's asdfadsf\"\n",
    "\n",
    "inp_test_seq3 = \"Thanks for your subscription to Ringtone UK your mobile will be charged �5/month Please confirm by replying YES or NO. If you reply NO you will not be charged. Thank you for reading message. Call me back immediately\"\n",
    "test_sequences = MyToken.texts_to_sequences(np.array([inp_test_seq3]))\n",
    "test_sequences_vec = sequence.pad_sequences(test_sequences, maxlen= Max_len)\n",
    "\n",
    "RNNmodel.predict(test_sequences_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}