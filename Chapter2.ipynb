{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package tagsets to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package tagsets is already up-to-date!\n"
    },
    {
     "data": {
      "text/plain": "[('I', 'PRP'),\n ('enjoy', 'VBP'),\n ('playing', 'VBG'),\n ('sports', 'NNS'),\n ('like', 'IN'),\n ('badminton', 'NN')]"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercis 10: Performing Rule-Based POS Tagging\n",
    "# 1: import nltk and punkt\n",
    "# NLTK has trainied POS tagger \n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "# 2: Store an input string in a variable named s\n",
    "s = 'I enjoy playing sports like badminton'\n",
    "# 3:Tokenize the sentence\n",
    "tokens = nltk.word_tokenize(s)\n",
    "# 4: Apply the POS tagger on the tokens and then print the tagset\n",
    "tags = nltk.pos_tag(tokens)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "PRP: pronoun, personal\n    hers herself him himself hisself it itself me myself one oneself ours\n    ourselves ownself self she thee theirs them themselves they thou thy us\nVBP: verb, present tense, not 3rd person singular\n    predominate wrap resort sue twist spill cure lengthen brush terminate\n    appear tend stray glisten obtain comprise detest tease attract\n    emphasize mold postpone sever return wag ...\nVBG: verb, present participle or gerund\n    telegraphing stirring focusing angering judging stalling lactating\n    hankerin' alleging veering capping approaching traveling besieging\n    encrypting interrupting erasing wincing ...\nNN: noun, common, singular or mass\n    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n    investment slide humour falloff slick wind hyena override subhumanity\n    machinist ...\n"
    }
   ],
   "source": [
    "# 5: To understand \"NN\" POS tag stands for\n",
    "nltk.help.upenn_tagset(\"PRP\")\n",
    "nltk.help.upenn_tagset(\"VBP\")\n",
    "nltk.help.upenn_tagset(\"VBG\")\n",
    "nltk.help.upenn_tagset(\"NN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('but', 'CC'),\n ('I', 'PRP'),\n ('mentioned', 'VBD'),\n ('that', 'IN'),\n ('Im', 'NNP'),\n ('going', 'VBG'),\n ('to', 'TO'),\n ('play', 'VB'),\n ('fun', 'JJ'),\n ('badmiton', 'NN'),\n ('for', 'IN'),\n ('the', 'DT'),\n ('play', 'NN'),\n ('on', 'IN'),\n ('this', 'DT'),\n ('Wed', 'NNP')]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check a sentence with hommonyms and see it tagset\n",
    "sentence2 = 'but I mentioned that Im going to play fun badmiton for the play on this Wed'\n",
    "tag2 = nltk.pos_tag(nltk.word_tokenize(sentence2))\n",
    "tag2\n",
    "# This show that POS taggers can differentiate between homonyms like Play(VerB) and play(NouN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "but ---> CCONJ ---> CC ---> conjunction, coordinating\nI ---> PRON ---> PRP ---> pronoun, personal\nmentioned ---> VERB ---> VBD ---> verb, past tense\nthat ---> SCONJ ---> IN ---> conjunction, subordinating or preposition\nI ---> PRON ---> PRP ---> pronoun, personal\nam ---> AUX ---> VBP ---> verb, non-3rd person singular present\ngoing ---> VERB ---> VBG ---> verb, gerund or present participle\nto ---> PART ---> TO ---> infinitival \"to\"\nplay ---> VERB ---> VB ---> verb, base form\nbadmiton ---> NOUN ---> NN ---> noun, singular or mass\nfor ---> ADP ---> IN ---> conjunction, subordinating or preposition\nthe ---> DET ---> DT ---> determiner\nplay ---> NOUN ---> NN ---> noun, singular or mass\non ---> ADP ---> IN ---> conjunction, subordinating or preposition\nthis ---> DET ---> DT ---> determiner\nWednesday ---> PROPN ---> NNP ---> noun, proper singular\n"
    }
   ],
   "source": [
    "# Exercise 11: Performing Stochastic POS tagging. spacy's POS tagger is a stochastic one.\n",
    "import spacy\n",
    "# load spaCy7's en\\core_web_sm model for English \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Fit the model on the sentence we want to assign POS tags to. \n",
    "doc = nlp(u\"but I mentioned that I am going to play badmiton for the play on this Wednesday\")\n",
    "# Tokenize the sentence, assign POS tags and print them\n",
    "    # print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "    #         token.shape_, token.is_alpha, token.is_stop)\n",
    "for token in doc: \n",
    "    print(token.text, \"--->\", token.pos_, \"--->\", token.tag_, \"--->\", spacy.explain(token.tag_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'verb, modal auxiliary'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to understand the tag ,\"VBD\",\"NN\",\"PRP\"\n",
    "spacy.explain(\"VBZ\")\n",
    "spacy.explain(\"MD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package tagsets to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package tagsets is already up-to-date!\n"
    }
   ],
   "source": [
    "# FROM Exercis 10: Performing Rule-Based POS Tagging\n",
    "# 1: import nltk and punkt\n",
    "# NLTK has trainied POS tagger \n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "# 2: Store an input string in a variable named s\n",
    "s = 'I enjoy playing some fun sports like badminton'\n",
    "\n",
    "# 3:Tokenize the sentence\n",
    "tokens = nltk.word_tokenize(s)\n",
    "# 4: Apply the POS tagger on the tokens and then print the tagset\n",
    "tagset = nltk.pos_tag(tokens)\n",
    "tagset\n",
    "\n",
    "# Exercise 12: perform Chunking with NLTK \n",
    "# 1 create a regular epression that will search for a noun phrase\n",
    "rule = r\"\"\"Noun Phrase: {(<DT>?<JJ>*<NN>?<NN>)|(<DT>?<JJ>*<NNS>)|<NN>}\"\"\"\n",
    "# look for <DT> determiner (ex: the) or <JJ> Adjective(ex: fun), then a single Noun\n",
    "# 2.Create an instance o RegxpParser and feed it the rule\n",
    "chunkParser = nltk.RegexpParser(rule)\n",
    "#3. Give chunkParser the tagset containing the tokens with their respective POS tags so that it can \n",
    "# perform chunking , and then draw the chunks:\n",
    "# chunked = chunkParser.parse(tagset)\n",
    "# chunked.draw()\n",
    "#4. different sentence\n",
    "a = \"The beautiful lady jumped on the sport car and he drove away into the high way\"\n",
    "tagset2 = nltk.pos_tag(nltk.word_tokenize(a))\n",
    "chunkParser2 = chunkParser.parse(tagset2)\n",
    "chunkParser2.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The beautiful lady lady nsubj\nthe sport car car pobj\nhe he nsubj\nthe high way way pobj\n"
    }
   ],
   "source": [
    "#Exercise 13: Perform Chunking with spaCy (spaCy is Supposed to be easier than NLTK)\n",
    "import spacy\n",
    "# load spaCy7's en\\core_web_sm model for English \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Fit the model on the sentence we want to assign POS tags to. \n",
    "doc = nlp(u\"The beautiful lady jumped on the sport car and he drove away into the high way\")\n",
    "#  Apply noun_chunks on this model, and for each chunk, print the text of the chunk\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_)\n",
    "# for token in doc.noun_chunks:\n",
    "#     # print(token.text)\n",
    "#     print(token.root.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package tagsets to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package tagsets is already up-to-date!\n"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "s2 = \"The beautiful lady jumped on the sport car and he drove away into the high way\"\n",
    "chink_tagset = nltk.pos_tag(nltk.word_tokenize(s2))\n",
    "\n",
    "# Exercise 14. Performing Chinking \n",
    "#1. Create rule that chunks the entire corpus and only creates chinks out of the words or phrases tagged as nouns or noun phrases:\n",
    "rule = r\"\"\"Chink: {<.*>+}\n",
    "}<VB.?|CC|RB|JJ|IN|DT|T0>+{\"\"\"\n",
    "# This regular expression is telling machine to ignore all words that are not Nouns or noun phrases(only extract N, N phrase as a chink)\n",
    "\n",
    "#2. Create an instance of RegexpParser and feed it the rule\n",
    "chinkParser = nltk.RegexpParser(rule)\n",
    "#3. Give ChinkParser the tagset and perform chinking \n",
    "chinked = chinkParser.parse(chink_tagset)\n",
    "chinked.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package treebank to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package treebank is already up-to-date!\n[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\nTagged sentences:  3914\nTagged words: 100676\nTraining completed\nAccuracy: 0.8939820022497188\n"
    }
   ],
   "source": [
    "# Activity 2: Build and Train POS Tagger* (Can I train my own tagger for CODE ?)\n",
    "\n",
    "#1. Pick a corpus to train (using nltk treebank corpus)\n",
    "import nltk \n",
    "import re\n",
    "import pprint \n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "nltk.download('treebank')\n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))\n",
    "# [(u'Pierre', u'NNP'), (u'Vinken', u'NNP'), (u',', u','), (u'61', u'CD'), (u'years', u'NNS'), (u'old', u'JJ'), (u',', u','), (u'will', u'MD'), (u'join', u'VB'), (u'the', u'DT'), (u'board', u'NN'), (u'as', u'IN'), (u'a', u'DT'), (u'nonexecutive', u'JJ'), (u'director', u'NN'), (u'Nov.', u'NNP'), (u'29', u'CD'), (u'.', u'.')]\n",
    "# Tagged sentences:  3914\n",
    "# Tagged words: 100676\n",
    "\n",
    "#2. Determine what are the feature the TAGGER will consder to assgin a tag to a word\n",
    "\"\"\"Before starting training a classifier, we must agree first on what features to use. Most obvious choices are: the word itself, the word before and the word after. That’s a good start, but we can do so much better. For example, the 2-letter suffix is a great indicator of past-tense verbs, ending in “-ed”. 3-letter suffix helps recognize the present participle ending in “-ing” \"\"\"\n",
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return  {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }\n",
    "\n",
    "# pprint.pprint(features(['This', 'is', 'a', 'sentence'], 2))\n",
    "# {'capitals_inside': False,\n",
    "#  'has_hyphen': False,\n",
    "#  'is_all_caps': False,\n",
    "#  'is_all_lower': True,\n",
    "#  'is_capitalized': False,\n",
    "#  'is_first': False,\n",
    "#  'is_last': False,\n",
    "#  'is_numeric': False,\n",
    "#  'next_word': 'sentence',\n",
    "#  'prefix-1': 'a',\n",
    "#  'prefix-2': 'a',\n",
    "#  'prefix-3': 'a',\n",
    "#  'prev_word': 'is',\n",
    "#  'suffix-1': 'a',\n",
    "#  'suffix-2': 'a',\n",
    "#  'suffix-3': 'a',\n",
    "#  'word': 'a'}\n",
    "\n",
    "#3. Create a fucntion to strip the tagged words of their tags, then feed them to the TAGGER\n",
    "\"\"\"Remove the tag for each tagged term.\n",
    "    :param tagged_sentence: a POS tagged sentence\n",
    "    :type tagged_sentence: list\n",
    "    :return: a list of tags\n",
    "    :rtype: list of strings\"\"\"\n",
    "def untag(tagged_sentence):\n",
    "    return [w for w, t in tagged_sentence] #?team\n",
    "\n",
    "# S_test = ((u'Pierre', u'NNP'), (u'Vinken', u'NNP'), (u',', u','), (u'61', u'CD'), (u'years', u'NNS'), (u'old', u'JJ'), (u',', u','), (u'will', u'MD'), (u'join', u'VB'), (u'the', u'DT'), (u'board', u'NN'), (u'as', u'IN'), (u'a', u'DT'), (u'nonexecutive', u'JJ'), (u'director', u'NN'), (u'Nov.', u'NNP'), (u'29', u'CD'), (u'.', u'.'),(u'Pierre', u'NNP'), (u'Vinken', u'NNP'), (u',', u','), (u'61', u'CD'), (u'years', u'NNS'), (u'old', u'JJ'), (u',', u','), (u'will', u'MD'), (u'join', u'VB'), (u'the', u'DT'), (u'board', u'NN'), (u'as', u'IN'), (u'a', u'DT'), (u'nonexecutive', u'JJ'), (u'director', u'NN'), (u'Nov.', u'NNP'), (u'29', u'CD'), (u'.', u'.'))\n",
    "\n",
    "# untag(S_test)\n",
    "\n",
    "# #4. Build a dataset and split into Training and Test data sets, Assign features(X), POS tags(Y)\n",
    "# \"\"\" Split the dataset for training and testing\"\"\"\n",
    "cutoff = int(.75 * len(tagged_sentences))\n",
    "training_sentences = tagged_sentences[:cutoff]\n",
    "test_sentences = tagged_sentences[cutoff:]\n",
    "\n",
    "# print(len(training_sentences))\n",
    "# print(len(test_sentences))\n",
    "\n",
    "def TransformToDataSet(tagged_sentences):\n",
    "    X, y = [], []\n",
    " \n",
    "    for tagged in tagged_sentences:\n",
    "        for index in range(len(tagged)):\n",
    "            X.append(features(untag(tagged), index))\n",
    "            y.append(tagged[index][1])\n",
    " \n",
    "    return X, y\n",
    "\n",
    "# # Get X,Y \n",
    "X_train, y_train = TransformToDataSet(training_sentences)\n",
    "\n",
    "#5. Use Decision Tree classifier to train the tagger. \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "clf = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='entropy'))\n",
    "])\n",
    " \n",
    "clf.fit(X_train[:10000], y_train[:10000])   # Use only the first 10K samples if you're running it multiple times. It takes a fair bit :)\n",
    " \n",
    "print('Training completed')\n",
    "\n",
    "X_test, Y_test = TransformToDataSet(test_sentences)\n",
    " \n",
    "print(\"Accuracy:\", clf.score(X_test, Y_test))\n",
    "# Accuracy expectation: 0.904186083882\n",
    "\n",
    "#6. Import the classifier, initialize it, fit the model on training and print the score. \n",
    "# def pos_tag(sentence):\n",
    "#     tags = clf.predict([features(sentence, index) for index in range(len(sentence))])\n",
    "#     print(sentence, tags)\n",
    "#     return zip(sentence, tags)\n",
    "\n",
    "# print(pos_tag(word_tokenize('This is my friend, John.')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[('This', 'DT'), ('is', 'VBZ'), ('my', 'NN'), ('friend', 'NN'), (',', ','), ('John', 'NNP'), ('.', '.')]\n"
    },
    {
     "data": {
      "text/plain": "[('This', 'DT'),\n ('is', 'VBZ'),\n ('my', 'NN'),\n ('friend', 'NN'),\n (',', ','),\n ('John', 'NNP'),\n ('.', '.')]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#6. Import the classifier, initialize it, fit the model on training and print the score. \n",
    "def pos_tag(sentence):\n",
    "    tags = clf.predict([features(sentence, index) for index in range(len(sentence))])\n",
    "    # NewSentence = [\"', '\".join(item) for item in zip(sentence, tags)]   # 1st way\n",
    "    # tagged_sentence  = list(map(list, zip(sentence, tags)))             # 2nd way \n",
    "    PosTagSentence = list(zip(sentence, tags)) # Final way \n",
    "\n",
    "    # print(NewSentence)\n",
    "    # print(tagged_sentence)\n",
    "    print(PosTagSentence)\n",
    "    \n",
    "    return PosTagSentence\n",
    " \n",
    "pos_tag(word_tokenize('This is my friend, John.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[('Mr', 'NNP'), ('NguyenHai', 'NNP'), ('may', 'MD'), ('visit', 'VB'), ('the', 'DT'), ('Taj', 'NNP'), ('Mahal', 'NNP'), ('after', 'IN'), ('taking', 'VBG'), ('a', 'DT'), ('SpiceJet', 'NNP'), ('flight', 'NN'), ('from', 'IN'), ('Tokyo', 'NNP'), ('.', '.')]\n"
    }
   ],
   "source": [
    "# Exercise 15: Perform Named Entity Recognition with NLTK\n",
    "# using ne_chunk algorithm of NLTK \n",
    "import nltk  \n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words') \n",
    "\n",
    "# 1. Store an input sentence in a var\n",
    "SentenceEx  = \"Mr NguyenHai may visit the Taj Mahal after taking a SpiceJet flight from Tokyo.\"\n",
    "# 2. Tokenize the sentence and assign POS tags to the tokens\n",
    "TagSentenceEx = nltk.pos_tag(nltk.word_tokenize(SentenceEx))\n",
    "\n",
    "# 3. Apply ne_chunk, True: not classify Name Entities, False: classify with categories \n",
    "NeSentenceEx = nltk.ne_chunk(TagSentenceEx, binary = False)\n",
    "NeSentenceEx.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Nguyen ORG Companies, agencies, institutions, etc.\nthe Taj Mahal PRODUCT Objects, vehicles, foods, etc. (not services)\nSpiceJet ORG Companies, agencies, institutions, etc.\nTokyo GPE Countries, cities, states\nNguyen Ngoc Hai PERSON People, including fictional\nSpiceJet ORG Companies, agencies, institutions, etc.\nTokyo GPE Countries, cities, states\n"
    }
   ],
   "source": [
    "# Exercise 16: Perform Named Entity Recognition with spaCy,(spaCy has several NERs)\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#1. Fit spaCy 's English model on the example sentence \n",
    "spaCyEx  = nlp(u\"Nguyen may visit the Taj Mahal after taking a SpiceJet flight from Tokyo.\")\n",
    "#2. For each entity in the sentence, print the text of entity and label\n",
    "for ent in spaCyEx.ents:\n",
    "    print(ent.text, ent.label_, spacy.explain(ent.label_))\n",
    "\n",
    "#3. Fit spaCy 's English model on the NEW example sentence     \n",
    "spaCyEx2  = nlp(u\"Nguyen Ngoc Hai visited the Taj Mahal after taking a SpiceJet flight from Tokyo.\")\n",
    "#4. repeat step 2\n",
    "for ent in spaCyEx2.ents:\n",
    "    print(ent.text, ent.label_, spacy.explain(ent.label_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "ddlesex', 'GPE')\n\n ('Water Co.', 'PERSON')\n\n ('Legg Mason Wood Walker', 'PERSON')\n\n ('Howard', 'PERSON')\n\n ('Weil', 'PERSON')\n\n ('Labouisse', 'PERSON')\n\n ('Midwesco', 'GPE')\n\n ('Chicago Corp', 'GPE')\n\n ('Nylev', 'PERSON')\n\n ('Municipal Fund', 'PERSON')\n\n ('Petroleum Corp.', 'PERSON')\n\n ('Drexel Burnham Lambert', 'PERSON')\n\n ('Service', 'GPE')\n\n ('Lovett Mitchell Webb', 'PERSON')\n\n ('Garrison', 'PERSON')\n\n ('Blunt Ellis', 'PERSON')\n\n ('Loewi Inc', 'PERSON')\n\n ('Western', 'GPE')\n\n ('Smith Barney', 'PERSON')\n\n ('Harris Upham', 'PERSON')\n\n ('Hanifen', 'PERSON')\n\n ('Imhoff Inc', 'PERSON')\n\n (\"Pat D'Amico\", 'PERSON')\n\n ('Diceon Electronics', 'PERSON')\n\n ('Calif.', 'GPE')\n\n ('Los Angeles County', 'GPE')\n\n ('Irvine', 'GPE')\n\n ('Roland Matthews', 'GPE')\n\n ('Peter Jonas', 'PERSON')\n\n ('August', 'GPE')\n\n ('Fabian Linden', 'PERSON')\n\n ('Mr. Linden', 'PERSON')\n\n ('U.S.', 'GPE')\n\n ('Toledo', 'GPE')\n\n ('Ohio', 'GPE')\n\n ('Home', 'GPE')\n\n ('Kathleen Camilli', 'PERSON')\n\n ('James Ednie', 'PERSON')\n\n ('Money', 'GPE')\n\n ('Syndicate', 'GPE')\n\n ('Charles Lieberman', 'PERSON')\n\n ('Market Committee', 'PERSON')\n\n ('Cleveland', 'GPE')\n\n ('Boston', 'GPE')\n\n ('Dallas', 'PERSON')\n\n ('San Francisco', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Lieberman', 'PERSON')\n\n ('Dow Jones Capital', 'PERSON')\n\n ('Markets Report', 'PERSON')\n\n ('August', 'GPE')\n\n ('Credit', 'GPE')\n\n ('Moody', 'PERSON')\n\n ('Moody', 'GPE')\n\n ('Total', 'GPE')\n\n ('Moody', 'PERSON')\n\n ('Junk', 'GPE')\n\n ('Moody', 'PERSON')\n\n ('John Lonski', 'PERSON')\n\n ('Moody', 'GPE')\n\n ('Mortgage', 'GPE')\n\n ('Ginnie', 'PERSON')\n\n ('Activity', 'GPE')\n\n ('Municipal', 'GPE')\n\n ('Municipal', 'GPE')\n\n ('California', 'GPE')\n\n ('Santa Ana Community', 'PERSON')\n\n ('Calif.', 'GPE')\n\n ('Donaldson Lufkin', 'PERSON')\n\n ('Detroit', 'GPE')\n\n ('West', 'GPE')\n\n ('German', 'GPE')\n\n ('Treasury', 'GPE')\n\n ('Japan', 'GPE')\n\n ('Britain', 'GPE')\n\n ('Standard', 'PERSON')\n\n ('Poor', 'PERSON')\n\n ('United', 'GPE')\n\n ('Hurricane Hugo', 'PERSON')\n\n ('Net', 'PERSON')\n\n ('California', 'GPE')\n\n ('Travelers', 'GPE')\n\n ('British', 'GPE')\n\n ('Trade', 'GPE')\n\n ('Industry', 'GPE')\n\n ('Michelin Tyre PLC', 'PERSON')\n\n ('PLC', 'GPE')\n\n ('Michelin Investment', 'PERSON')\n\n ('Michelin', 'PERSON')\n\n ('France', 'GPE')\n\n ('Michelin', 'PERSON')\n\n ('Michelin', 'GPE')\n\n ('Tyre', 'GPE')\n\n ('John Dingell', 'PERSON')\n\n ('Bush', 'PERSON')\n\n ('Mr. Dingell', 'PERSON')\n\n ('Mr. Dingell', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Bush', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Midwestern', 'GPE')\n\n ('American City', 'GPE')\n\n ('Michael K. Russell', 'PERSON')\n\n ('Charlotte', 'GPE')\n\n ('Mr. Russell', 'PERSON')\n\n ('Shaw Publishing', 'PERSON')\n\n ('Charlotte', 'PERSON')\n\n ('American City', 'GPE')\n\n ('Ray', 'PERSON')\n\n ('Shaw', 'GPE')\n\n ('American City', 'GPE')\n\n ('Mr. Russell', 'PERSON')\n\n ('System', 'PERSON')\n\n ('New York', 'GPE')\n\n ('Futures', 'GPE')\n\n ('Indexing', 'GPE')\n\n ('Program', 'GPE')\n\n ('Quant', 'GPE')\n\n ('Trade', 'GPE')\n\n ('Uptick', 'GPE')\n\n ('New York', 'GPE')\n\n ('Saul Steinberg', 'PERSON')\n\n ('United Airlines', 'GPE')\n\n ('Mr. Steinberg', 'PERSON')\n\n ('Takeover', 'GPE')\n\n ('Reliance', 'GPE')\n\n ('Mr. Steinberg', 'PERSON')\n\n ('Mr. Steinberg', 'PERSON')\n\n ('Stephen Wolf', 'PERSON')\n\n ('Mr. Steinberg', 'PERSON')\n\n ('British', 'GPE')\n\n ('Reliance', 'GPE')\n\n ('Reliance', 'GPE')\n\n ('Market', 'GPE')\n\n ('Reliance', 'GPE')\n\n ('Reliance', 'GPE')\n\n ('New York', 'GPE')\n\n ('Coniston', 'PERSON')\n\n ('New York', 'GPE')\n\n ('Reliance', 'GPE')\n\n ('Reliance', 'GPE')\n\n ('Mr. Steinberg', 'PERSON')\n\n ('Reliance', 'GPE')\n\n ('Mr.', 'PERSON')\n\n ('Steinberg', 'PERSON')\n\n ('Mr. Wolf', 'PERSON')\n\n ('Mr. Wolf', 'PERSON')\n\n ('Tiger International Inc', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Williams Corp.', 'PERSON')\n\n ('New York', 'GPE')\n\n ('Williams', 'GPE')\n\n ('Primerica', 'GPE')\n\n ('Williams', 'PERSON')\n\n ('Williams', 'PERSON')\n\n ('Williams', 'GPE')\n\n ('New York', 'GPE')\n\n ('Primerica', 'GPE')\n\n ('Williams', 'PERSON')\n\n ('Duluth', 'GPE')\n\n ('Primerica', 'GPE')\n\n ('Trace Inc.', 'PERSON')\n\n ('San Antonio', 'PERSON')\n\n ('Texas', 'GPE')\n\n ('Asher Edelman', 'PERSON')\n\n ('Martin Ackerman', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Ackerman', 'PERSON')\n\n ('Mr. Edelman', 'PERSON')\n\n ('New York', 'GPE')\n\n ('Mr.', 'PERSON')\n\n ('Edelman', 'PERSON')\n\n ('Marty Ackerman', 'PERSON')\n\n ('Mr. Ackerman', 'PERSON')\n\n ('Mr. Edelman', 'PERSON')\n\n ('Dow', 'PERSON')\n\n ('Jones', 'PERSON')\n\n ('Dow Jones', 'PERSON')\n\n ('Dow', 'PERSON')\n\n ('Jones', 'GPE')\n\n ('Telerate', 'GPE')\n\n ('New York', 'GPE')\n\n ('Telerate', 'GPE')\n\n ('Dow', 'PERSON')\n\n ('Jones', 'PERSON')\n\n ('Barron', 'PERSON')\n\n ('Donald Beall', 'PERSON')\n\n ('Rockwell', 'PERSON')\n\n ('Sales', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Beall', 'PERSON')\n\n ('Overall', 'GPE')\n\n ('Aerospace', 'GPE')\n\n ('Dell', 'PERSON')\n\n ('Austin', 'GPE')\n\n ('World', 'GPE')\n\n ('Brazil', 'PERSON')\n\n ('Mexico', 'GPE')\n\n ('Brazilian', 'GPE')\n\n ('Brazilian', 'GPE')\n\n ('Arthur Stevenson', 'PERSON')\n\n ('New York', 'GPE')\n\n ('Brazil', 'GPE')\n\n ('Mr. Stevenson', 'PERSON')\n\n ('Brazil', 'GPE')\n\n ('Brazil', 'PERSON')\n\n ('Judith Ganes', 'PERSON')\n\n ('Hutton', 'PERSON')\n\n ('New York', 'GPE')\n\n ('Ganes', 'PERSON')\n\n ('Brazil', 'GPE')\n\n ('Ganes', 'PERSON')\n\n ('Brazilian', 'GPE')\n\n ('Thomas', 'PERSON')\n\n ('Oxnard', 'GPE')\n\n ('Hackensack', 'GPE')\n\n ('N.J.', 'GPE')\n\n ('Brazil', 'PERSON')\n\n ('Mr. Oxnard', 'PERSON')\n\n ('Brazilian', 'GPE')\n\n ('Mr.', 'PERSON')\n\n ('Oxnard', 'PERSON')\n\n ('Brazil', 'GPE')\n\n ('Brazil', 'PERSON')\n\n ('Mr. Oxnard', 'PERSON')\n\n ('Mexico', 'GPE')\n\n ('ENERGY', 'GPE')\n\n ('Petroleum', 'GPE')\n\n ('New York', 'GPE')\n\n ('Gasoline', 'GPE')\n\n ('West', 'GPE')\n\n ('Texas Intermediate', 'PERSON')\n\n ('U.S.', 'GPE')\n\n ('Trading', 'GPE')\n\n ('Europe', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Chinese', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Britain', 'GPE')\n\n ('Traders', 'PERSON')\n\n ('Soviet Union', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('COPPER', 'GPE')\n\n ('Exxon Corp.', 'PERSON')\n\n ('Reuter', 'PERSON')\n\n ('Bougainville', 'GPE')\n\n ('Younkers', 'GPE')\n\n ('Midwestern', 'GPE')\n\n ('Iowa Cos.', 'PERSON')\n\n ('Des Moines', 'PERSON')\n\n ('Equitable', 'PERSON')\n\n ('Iowa', 'GPE')\n\n ('Nebraska', 'GPE')\n\n ('Younkers', 'GPE')\n\n ('Fred S. Hubbell', 'PERSON')\n\n ('Equitable', 'PERSON')\n\n ('Younkers', 'GPE')\n\n ('Tony', 'PERSON')\n\n ('Equus Investment II Limited Partnership', 'PERSON')\n\n ('Equus', 'PERSON')\n\n ('Equus Capital', 'PERSON')\n\n ('Houston', 'PERSON')\n\n ('Tony Lama', 'PERSON')\n\n ('Texas', 'GPE')\n\n ('Western', 'GPE')\n\n ('Tony Lama', 'PERSON')\n\n ('Tony Lama', 'PERSON')\n\n ('Tony Lama', 'PERSON')\n\n ('Reuters', 'PERSON')\n\n ('Holdings PLC', 'PERSON')\n\n ('Michael Reupke', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Mr. Reupke', 'PERSON')\n\n ('Mr. Reupke', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Reupke', 'PERSON')\n\n ('Mark Shepperd', 'PERSON')\n\n ('London', 'GPE')\n\n ('London', 'GPE')\n\n ('Stock Exchange', 'PERSON')\n\n ('U.S.', 'GPE')\n\n ('American', 'GPE')\n\n ('London', 'GPE')\n\n ('Mr. Reupke', 'PERSON')\n\n ('Nigel Judah', 'PERSON')\n\n ('Peter', 'PERSON')\n\n ('Holland', 'GPE')\n\n ('Patrick Mannix', 'PERSON')\n\n ('Dunkin', 'GPE')\n\n ('Randolph', 'GPE')\n\n ('Mass', 'GPE')\n\n ('Cara', 'GPE')\n\n ('Unicorp', 'GPE')\n\n ('Toronto', 'GPE')\n\n ('Savin', 'PERSON')\n\n ('Revenue', 'PERSON')\n\n ('Savin', 'PERSON')\n\n ('Savin', 'PERSON')\n\n ('Hadson', 'PERSON')\n\n ('Hadson', 'PERSON')\n\n ('Standard', 'PERSON')\n\n ('Poor', 'PERSON')\n\n ('New York', 'GPE')\n\n ('New York', 'GPE')\n\n ('Philip Puccio', 'PERSON')\n\n ('Uncertainty', 'GPE')\n\n ('Mr. Puccio', 'PERSON')\n\n ('Trading', 'GPE')\n\n ('Richard Eakle', 'PERSON')\n\n ('Fair Haven', 'PERSON')\n\n ('Campbell', 'PERSON')\n\n ('Soup', 'PERSON')\n\n ('Gordon McGovern', 'PERSON')\n\n ('John McMillin', 'PERSON')\n\n ('Woolworth', 'PERSON')\n\n ('Ferro', 'PERSON')\n\n ('Upjohn', 'GPE')\n\n ('New York', 'GPE')\n\n ('Donald Trump', 'PERSON')\n\n ('American Airlines', 'GPE')\n\n ('Mr.', 'PERSON')\n\n ('Trump', 'PERSON')\n\n ('Drexel', 'PERSON')\n\n ('Burnham Lambert', 'PERSON')\n\n ('Michael Derchin', 'PERSON')\n\n ('United Airlines', 'GPE')\n\n ('Georgia', 'PERSON')\n\n ('Gulf', 'PERSON')\n\n ('Dallas', 'PERSON')\n\n ('Harold Simmons', 'PERSON')\n\n ('Great', 'GPE')\n\n ('Mead', 'PERSON')\n\n ('Scott Paper', 'PERSON')\n\n ('Texaco', 'GPE')\n\n ('Texaco', 'GPE')\n\n ('Santa Fe Pacific', 'PERSON')\n\n ('Santa Fe', 'PERSON')\n\n ('Allergan', 'PERSON')\n\n ('Drug Administration', 'PERSON')\n\n ('Volume', 'PERSON')\n\n ('Old', 'PERSON')\n\n ('Spaghetti Warehouse', 'PERSON')\n\n ('New', 'GPE')\n\n ('Energy Partners', 'PERSON')\n\n ('Nissan', 'PERSON')\n\n ('Motor Co.', 'PERSON')\n\n ('Japan', 'GPE')\n\n ('Nissan', 'GPE')\n\n ('Profit', 'GPE')\n\n ('Sales', 'PERSON')\n\n ('Nissan', 'GPE')\n\n ('Atsushi Muramatsu', 'PERSON')\n\n ('Nissan', 'GPE')\n\n ('Heritage', 'PERSON')\n\n ('New York', 'GPE')\n\n ('Heritage', 'GPE')\n\n ('Heritage', 'PERSON')\n\n ('Heritage', 'PERSON')\n\n ('New', 'GPE')\n\n ('Heritage', 'GPE')\n\n ('Harry', 'PERSON')\n\n ('Millis', 'PERSON')\n\n ('Cleveland', 'GPE')\n\n ('Kansas', 'GPE')\n\n ('Aerojet Ordnance', 'PERSON')\n\n ('San Francisco', 'PERSON')\n\n ('Transamerica', 'PERSON')\n\n ('Hurricane Hugo', 'PERSON')\n\n ('California', 'GPE')\n\n ('Hasbrouk Heights', 'PERSON')\n\n ('N.J.', 'GPE')\n\n ('Sales', 'PERSON')\n\n ('Sales', 'PERSON')\n\n ('Meridian', 'GPE')\n\n ('Meridian', 'GPE')\n\n ('Meridian', 'GPE')\n\n ('Meridian', 'GPE')\n\n ('Meridian', 'GPE')\n\n ('Haden MacLellan Holding PLC', 'PERSON')\n\n ('Surrey', 'GPE')\n\n ('England', 'GPE')\n\n ('Meridian', 'GPE')\n\n ('William Feniger', 'PERSON')\n\n ('Toledo', 'GPE')\n\n ('Meridian', 'GPE')\n\n ('Weisfield', 'PERSON')\n\n ('Ratners', 'PERSON')\n\n ('Ratners', 'GPE')\n\n ('Gerald Ratner', 'PERSON')\n\n ('Ratners', 'GPE')\n\n ('London', 'GPE')\n\n ('Ratners', 'PERSON')\n\n ('Weisfield', 'GPE')\n\n ('Weisfield', 'PERSON')\n\n ('Ratners', 'PERSON')\n\n ('U.S.', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Carnival', 'PERSON')\n\n ('Cruise Lines', 'PERSON')\n\n ('Finland', 'GPE')\n\n ('Carnival', 'PERSON')\n\n ('Waertsilae Marine Industries', 'PERSON')\n\n ('Finnish', 'GPE')\n\n ('Carnival', 'PERSON')\n\n ('Carnival', 'PERSON')\n\n ('Finland', 'GPE')\n\n ('Carnival', 'PERSON')\n\n ('Carnival', 'PERSON')\n\n ('Carnival', 'PERSON')\n\n ('Finnish', 'GPE')\n\n ('Carnival', 'PERSON')\n\n ('Valley', 'PERSON')\n\n ('Loan Association', 'PERSON')\n\n ('Calif.', 'GPE')\n\n ('Valley', 'PERSON')\n\n ('Valley', 'PERSON')\n\n ('New', 'GPE')\n\n ('Midwest', 'GPE')\n\n ('America', 'GPE')\n\n ('Peoria', 'GPE')\n\n ('Midwest', 'GPE')\n\n ('America', 'GPE')\n\n ('Kalamazoo', 'GPE')\n\n ('America', 'GPE')\n\n ('America', 'GPE')\n\n ('America', 'GPE')\n\n ('America', 'GPE')\n\n ('Coleco', 'GPE')\n\n ('Coleco', 'PERSON')\n\n ('Coleco', 'PERSON')\n\n ('New York', 'GPE')\n\n ('Bush', 'PERSON')\n\n ('Ortega', 'PERSON')\n\n ('U.S.', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Honduras', 'GPE')\n\n ('Sandinista', 'GPE')\n\n ('East', 'GPE')\n\n ('German', 'GPE')\n\n ('Krenz', 'PERSON')\n\n ('Moscow', 'GPE')\n\n ('East Germany', 'PERSON')\n\n ('Gorbachev', 'PERSON')\n\n ('East Germans', 'GPE')\n\n ('Czechoslovakia', 'PERSON')\n\n ('Health', 'GPE')\n\n ('Michigan', 'GPE')\n\n ('Bush', 'PERSON')\n\n ('Poland', 'GPE')\n\n ('South', 'GPE')\n\n ('Africa', 'PERSON')\n\n ('Namibian', 'GPE')\n\n ('Angola', 'PERSON')\n\n ('Pretoria', 'GPE')\n\n ('South', 'GPE')\n\n ('African', 'GPE')\n\n ('Guerrilla', 'GPE')\n\n ('Namibia', 'GPE')\n\n ('Lebanon', 'GPE')\n\n ('Saudi', 'GPE')\n\n ('Arabian Embassy', 'PERSON')\n\n ('Riyadh', 'PERSON')\n\n ('Beirut', 'GPE')\n\n ('Moslem', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Nixon', 'PERSON')\n\n ('Chinese', 'GPE')\n\n ('Beijing', 'GPE')\n\n ('Sino-U.S.', 'GPE')\n\n ('China', 'GPE')\n\n ('Beijing', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('China', 'GPE')\n\n ('Mexico', 'GPE')\n\n ('Salinas', 'PERSON')\n\n ('Salinas', 'PERSON')\n\n ('Pakistan', 'GPE')\n\n ('Bhutto', 'PERSON')\n\n ('Islamabad', 'GPE')\n\n ('Bush', 'PERSON')\n\n ('Soviet', 'GPE')\n\n ('Gorbachev', 'PERSON')\n\n ('Malta', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Bush', 'PERSON')\n\n ('South America', 'GPE')\n\n ('Pan', 'GPE')\n\n ('Scotland', 'GPE')\n\n ('Israel', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('James A. Attwood', 'PERSON')\n\n ('Mutual Life Insurance', 'PERSON')\n\n ('New York', 'GPE')\n\n ('New York City', 'GPE')\n\n ('Sony', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Sony', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Sony', 'GPE')\n\n ('Sony', 'PERSON')\n\n ('Jon Peters', 'PERSON')\n\n ('Peter Guber', 'PERSON')\n\n ('Sony', 'PERSON')\n\n ('Warner', 'PERSON')\n\n ('Xerox', 'PERSON')\n\n ('Forster', 'PERSON')\n\n ('Xerox', 'PERSON')\n\n ('Hurricane Hugo', 'PERSON')\n\n ('Hurricane Hugo', 'PERSON')\n\n ('California', 'GPE')\n\n ('Komatsu', 'PERSON')\n\n ('Sales', 'PERSON')\n\n ('Brisk', 'GPE')\n\n ('Domestic', 'GPE')\n\n ('Demand', 'GPE')\n\n ('Europe', 'GPE')\n\n ('Komatsu', 'PERSON')\n\n ('Net', 'GPE')\n\n ('Factory', 'GPE')\n\n ('Campbell', 'PERSON')\n\n ('Soup', 'PERSON')\n\n ('Gordon McGovern', 'PERSON')\n\n ('Dorrance', 'GPE')\n\n ('Campbell', 'PERSON')\n\n ('Big Board', 'PERSON')\n\n ('Phelan', 'PERSON')\n\n ('Georgia', 'PERSON')\n\n ('Gulf', 'PERSON')\n\n ('Harold Simmons', 'PERSON')\n\n ('Bush', 'PERSON')\n\n ('Steinberg', 'PERSON')\n\n ('United Air', 'GPE')\n\n ('Takeover', 'GPE')\n\n ('Pennsylvania', 'GPE')\n\n ('Random', 'PERSON')\n\n ('Robert Bernstein', 'PERSON')\n\n ('Cray', 'PERSON')\n\n ('Research', 'PERSON')\n\n ('Seymour Cray', 'PERSON')\n\n ('Light', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Dow', 'PERSON')\n\n ('Shearson Lehman Hutton Treasury', 'PERSON')\n\n ('Dow Jones', 'PERSON')\n\n ('Dollar', 'GPE')\n\n ('Loan Association', 'PERSON')\n\n ('Thomas Spiegel', 'PERSON')\n\n ('Hills', 'PERSON')\n\n ('Calif.', 'GPE')\n\n ('Columbia', 'PERSON')\n\n ('Mr. Spiegel', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Columbia', 'GPE')\n\n ('Mr. Spiegel', 'PERSON')\n\n ('Columbia', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Mr.', 'PERSON')\n\n ('Spiegel', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Columbia', 'GPE')\n\n ('Columbia', 'GPE')\n\n ('Carl Lindner', 'PERSON')\n\n ('Irwin Jacobs', 'PERSON')\n\n ('Pacific Financial Research', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Mr. Spiegel', 'PERSON')\n\n ('Columbia', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Columbia', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('New', 'GPE')\n\n ('Columbia', 'PERSON')\n\n ('Columbia', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Drexel', 'PERSON')\n\n ('Western Union Telegraph', 'GPE')\n\n ('Gillett Holdings', 'PERSON')\n\n ('Texas Air', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Columbia', 'GPE')\n\n ('Mr. Spiegel', 'PERSON')\n\n ('Columbia', 'PERSON')\n\n ('Mellon Bank', 'PERSON')\n\n ('Columbia', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Columbia', 'GPE')\n\n ('California', 'GPE')\n\n ('Columbia', 'GPE')\n\n ('Mr. Spiegel', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Lewis Ranieri', 'PERSON')\n\n ('New York', 'GPE')\n\n ('Mr.', 'PERSON')\n\n ('Spiegel', 'PERSON')\n\n ('Mr. Spiegel', 'PERSON')\n\n ('Columbia', 'GPE')\n\n ('Jonathan Gray', 'PERSON')\n\n ('Bernstein', 'PERSON')\n\n ('Columbia', 'PERSON')\n\n ('Mr. Spiegel', 'PERSON')\n\n ('Pauline', 'PERSON')\n\n ('Los Angeles', 'GPE')\n\n ('Columbia', 'GPE')\n\n ('Loan', 'PERSON')\n\n ('Symbol', 'PERSON')\n\n ('Business', 'GPE')\n\n ('Year', 'PERSON')\n\n ('Genetics', 'PERSON')\n\n ('Cambridge', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Sandoz', 'PERSON')\n\n ('Mr. Thomas', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Thomas', 'GPE')\n\n ('Mr. Thomas', 'PERSON')\n\n ('David Runkel', 'PERSON')\n\n ('Metallgesellschaft', 'PERSON')\n\n ('Lentjes AG', 'PERSON')\n\n ('Metallgesellschaft', 'GPE')\n\n ('Frankfurt', 'GPE')\n\n ('West', 'GPE')\n\n ('Lentjes', 'PERSON')\n\n ('Lurgi', 'PERSON')\n\n ('Lentjes', 'PERSON')\n\n ('Lentjes', 'GPE')\n\n ('Frankfurt', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Hong Kong', 'GPE')\n\n ('Taiwan', 'GPE')\n\n ('South Korea', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Taiwan', 'GPE')\n\n ('South Korea', 'GPE')\n\n ('Hong Kong', 'GPE')\n\n ('Du Pont', 'PERSON')\n\n ('Wilmington', 'GPE')\n\n ('France', 'GPE')\n\n ('Upjohn', 'PERSON')\n\n ('Upjohn', 'GPE')\n\n ('Upjohn', 'GPE')\n\n ('Upjohn', 'PERSON')\n\n ('Cooper', 'PERSON')\n\n ('Jonathan S. Gelles', 'PERSON')\n\n ('Upjohn', 'PERSON')\n\n ('Upjohn', 'PERSON')\n\n ('Upjohn', 'PERSON')\n\n ('New York', 'GPE')\n\n ('Upjohn', 'GPE')\n\n ('Upjohn', 'GPE')\n\n ('Chandler', 'PERSON')\n\n ('Jerry', 'PERSON')\n\n ('Chapman', 'PERSON')\n\n ('Henry Holt', 'PERSON')\n\n ('William Sternberg', 'PERSON')\n\n ('Bronx', 'GPE')\n\n ('Wedtech', 'PERSON')\n\n ('Washington', 'GPE')\n\n ('D.C.', 'GPE')\n\n ('Wedtech', 'GPE')\n\n ('Bribe', 'GPE')\n\n ('Mr. Sternberg', 'PERSON')\n\n ('Matthew C. Harrison Jr.', 'PERSON')\n\n ('Wedtech', 'PERSON')\n\n ('John Mariotta', 'PERSON')\n\n ('Fred Neuberger', 'PERSON')\n\n ('Wedtech', 'PERSON')\n\n ('Wedtech', 'PERSON')\n\n ('Mr. Neuberger', 'PERSON')\n\n ('Great Society', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Neuberger', 'PERSON')\n\n ('Italian', 'GPE')\n\n ('Mr. Mariotta', 'PERSON')\n\n ('Puerto Rico', 'GPE')\n\n ('Mariotta', 'PERSON')\n\n ('Neuberger', 'PERSON')\n\n ('Wedtech', 'PERSON')\n\n ('Jimmy Carter', 'PERSON')\n\n ('Carter', 'PERSON')\n\n ('South Bronx', 'GPE')\n\n ('Robert Wallach', 'PERSON')\n\n ('Wedtech', 'PERSON')\n\n ('Reagan', 'PERSON')\n\n ('Lyn Nofzinger', 'PERSON')\n\n ('Wedtech', 'GPE')\n\n ('Mr. Mariotta', 'PERSON')\n\n ('Wedtech', 'GPE')\n\n ('Louis Lobsenz', 'PERSON')\n\n ('Rusty', 'GPE')\n\n ('Frenzy', 'PERSON')\n\n ('Wedtech', 'GPE')\n\n ('Wedtech', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('East', 'GPE')\n\n ('Mr.', 'PERSON')\n\n ('Stern', 'PERSON')\n\n ('New York', 'GPE')\n\n ('Urban Development', 'PERSON')\n\n ('Finnish', 'GPE')\n\n ('Waertsilae Marine', 'PERSON')\n\n ('Christian Andersson', 'PERSON')\n\n ('Waertsilae Marine', 'PERSON')\n\n ('Finland', 'GPE')\n\n ('Waertsilae', 'PERSON')\n\n ('Marine', 'PERSON')\n\n ('Carnival Cruise', 'PERSON')\n\n ('Lines Inc', 'PERSON')\n\n ('Carnival', 'GPE')\n\n ('Waertsilae', 'PERSON')\n\n ('Marine', 'PERSON')\n\n ('California', 'GPE')\n\n ('James Nichol', 'PERSON')\n\n ('Lee Karns', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Nichol', 'PERSON')\n\n ('Mr. Nichol', 'PERSON')\n\n ('Irvine', 'GPE')\n\n ('Calif.', 'GPE')\n\n ('St. Louis', 'GPE')\n\n ('Mr.', 'PERSON')\n\n ('Karns', 'PERSON')\n\n ('Care', 'PERSON')\n\n ('First Hospital', 'PERSON')\n\n ('Norfolk', 'GPE')\n\n ('New York', 'GPE')\n\n ('Ralston', 'PERSON')\n\n ('Ralston', 'PERSON')\n\n ('Ralston', 'PERSON')\n\n ('Greenville', 'GPE')\n\n ('N.C.', 'GPE')\n\n ('Cincinnati', 'GPE')\n\n ('Ralston', 'PERSON')\n\n ('Ralston', 'PERSON')\n\n ('South America', 'GPE')\n\n ('Ralston', 'GPE')\n\n ('New York', 'GPE')\n\n ('Ravenswood Financial', 'PERSON')\n\n ('Chicago', 'GPE')\n\n ('Soviet Union', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Midwest', 'GPE')\n\n ('River', 'GPE')\n\n ('Railroad', 'GPE')\n\n ('Soviet Union', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Soviet Union', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Soviet Union', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('William Dunton', 'PERSON')\n\n ('U.S.', 'GPE')\n\n ('St. Louis', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Barge', 'GPE')\n\n ('Similar', 'GPE')\n\n ('Trade', 'GPE')\n\n ('Trade', 'GPE')\n\n ('Corn', 'GPE')\n\n ('Soviet', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Iowa', 'GPE')\n\n ('Lyle Reed', 'PERSON')\n\n ('Chicago', 'GPE')\n\n('Pacific Railroad', 'PERSON')\n\n ('Waterloo', 'GPE')\n\n ('Iowa', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('Bill Biedermann', 'PERSON')\n\n ('Allendale', 'PERSON')\n\n ('Ports', 'GPE')\n\n ('New Orleans', 'GPE')\n\n ('Indiana', 'GPE')\n\n ('Baltimore', 'GPE')\n\n ('Soviet Union', 'GPE')\n\n ('Soviet Union', 'GPE')\n\n ('U.S.', 'GPE')\n\n ('ENERGY', 'GPE')\n\n ('European', 'GPE')\n\n ('Heating', 'GPE')\n\n ('New York', 'GPE')\n\n ('West', 'GPE')\n\n ('Texas Intermediate', 'PERSON')\n\n ('Gasoline', 'GPE')\n\n (\"William O'Neill\", 'PERSON')\n\n ('New York', 'GPE')\n\n ('Silver', 'GPE')\n\n ('Silver', 'GPE')\n\n ('COPPER', 'GPE')\n\n ('Chile', 'GPE')\n\n ('Los Bronces', 'GPE')\n\n ('El Soldado', 'PERSON')\n\n ('Chicago', 'GPE')\n\n ('Chicago', 'GPE')\n\n ('Chicago', 'GPE')\n\n ('Tower', 'GPE')\n\n ('Sales', 'PERSON')\n\n ('Peter', 'PERSON')\n\n ('Lorain', 'GPE')\n\n ('Ohio', 'GPE')\n\n ('Japan', 'GPE')\n\n ('Kobe Steel Ltd', 'PERSON')\n\n ('Profit', 'GPE')\n\n ('Steel Corp.', 'PERSON')\n\n ('Inland Steel', 'GPE')\n\n ('New York', 'GPE')\n\n ('Charles Bradford', 'PERSON')\n\n ('Merrill Lynch Capital Markets', 'PERSON')\n\n ('Carl Icahn', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Icahn', 'PERSON')\n\n ('Profit', 'GPE')\n\n ('Sales', 'PERSON')\n\n ('John', 'PERSON')\n\n ('Barrett', 'PERSON')\n\n ('Leon', 'PERSON')\n\n ('Business', 'GPE')\n\n ('David', 'PERSON')\n\n ('Delmont A. Davis', 'PERSON')\n\n ('August', 'GPE')\n\n ('Bush', 'PERSON')\n\n ('Philip Kurland', 'PERSON')\n\n ('Chicago', 'GPE')\n\n ('Bush', 'PERSON')\n\n ('Mr.', 'PERSON')\n\n ('Bush', 'PERSON')\n\n ('Edward Kennedy', 'PERSON')\n\n ('Mr. Kurland', 'PERSON')\n\n ('Mr. Tribe', 'PERSON')\n\n ('Kennedy', 'PERSON')\n\n ('Bush', 'PERSON')\n\n ('Trailer Train', 'PERSON')\n\n ('Chicago', 'GPE')\n\n ('Trinity', 'PERSON')\n"
    }
   ],
   "source": [
    "# Activity 3: Performing NER on a tagged Corpus \n",
    "import nltk, re\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "nltk.download('treebank')\n",
    "\n",
    "#print(nltk.corpus.treebank.tagged_sents())\n",
    "TaggedSents = nltk.corpus.treebank.tagged_sents()\n",
    "\n",
    "for index in range(len(TaggedSents)):\n",
    "    FirstSentence = TaggedSents[index] # print(\"First Sentence\",'\\n',FirstSentence,'\\n')\n",
    "\n",
    "    NerFirst = nltk.ne_chunk(FirstSentence, binary = False)\n",
    "    # print('\\n',NerFirst)\n",
    "    # NerFirst.draw()\n",
    "    named_entities = []\n",
    "\n",
    "    for tagged_tree in NerFirst:\n",
    "        # print(tagged_tree)\n",
    "        if hasattr(tagged_tree, 'label'):\n",
    "            # print(\"-----ADD THIS TAGGED TREE-----\")\n",
    "            entity_name = ' '.join(child[0] for child in tagged_tree.leaves())\n",
    "            entity_type = tagged_tree.label()\n",
    "            named_entities.append((entity_name,entity_type))\n",
    "            # Stack.append(' '.join([child[0].lower() for child in tree]))\n",
    "            \n",
    "    #Specify any tag which is required 'GPE','PERSON', 'NE' is for binary = True \n",
    "    for tag in named_entities:\n",
    "        if tag[1]=='PERSON':  \n",
    "            print('\\n',tag)\n",
    "        if tag[1]=='GPE':  \n",
    "            print('\\n',tag)\n",
    "\n",
    "# MORE INFO: \n",
    "# https://nlpforhackers.io/named-entity-extraction/\n",
    "# https://stackoverflow.com/questions/48660547/how-can-i-extract-gpelocation-using-nltk-ne-chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-----1ST SENTENCE, BINARY = TRUE----- \n (S\n  (NE Pierre/NNP Vinken/NNP)\n  ,/,\n  61/CD\n  years/NNS\n  old/JJ\n  ,/,\n  will/MD\n  join/VB\n  the/DT\n  board/NN\n  as/IN\n  a/DT\n  nonexecutive/JJ\n  director/NN\n  Nov./NNP\n  29/CD\n  ./.)\n-----2ND SENTENCE, BINARY = False----- \n (S\n  (PERSON Mr./NNP)\n  (PERSON Vinken/NNP)\n  is/VBZ\n  chairman/NN\n  of/IN\n  (ORGANIZATION Elsevier/NNP)\n  N.V./NNP\n  ,/,\n  the/DT\n  (GPE Dutch/NNP)\n  publishing/VBG\n  group/NN\n  ./.)\n-----3RD SENTENCE, BINARY = False----- \n (S\n  (PERSON Rudolph/NNP)\n  (GPE Agnew/NNP)\n  ,/,\n  55/CD\n  years/NNS\n  old/JJ\n  and/CC\n  former/JJ\n  chairman/NN\n  of/IN\n  (ORGANIZATION Consolidated/NNP Gold/NNP Fields/NNP)\n  PLC/NNP\n  ,/,\n  was/VBD\n  named/VBN\n  *-1/-NONE-\n  a/DT\n  nonexecutive/JJ\n  director/NN\n  of/IN\n  this/DT\n  (GPE British/JJ)\n  industrial/JJ\n  conglomerate/NN\n  ./.)\n[nltk_data] Downloading package treebank to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package treebank is already up-to-date!\n[nltk_data] Downloading package maxent_ne_chunker to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n[nltk_data] Downloading package words to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package words is already up-to-date!\n"
    }
   ],
   "source": [
    "# Activity 3: Performing NER on a tagged Corpus (BOOK ANSWER)\n",
    "#1. Import necessary python packages\n",
    "import nltk, re\n",
    "nltk.download('treebank')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "#2. Print nltk.corpus.treebank.tagged_sents()\n",
    "TaggedSents = nltk.corpus.treebank.tagged_sents()\n",
    "FirstSent = TaggedSents[0]\n",
    "NeFirst = nltk.ne_chunk(FirstSent, binary=True)\n",
    "\n",
    "print(\"-----1ST SENTENCE, BINARY = TRUE-----\",'\\n',NeFirst)\n",
    "\n",
    "#3. Store 1st sentence to a var\n",
    "SecondSent = TaggedSents[1]\n",
    "NeSeconde = nltk.ne_chunk(SecondSent,binary=False)\n",
    "print(\"-----2ND SENTENCE, BINARY = False-----\",'\\n',NeSeconde)\n",
    "\n",
    "#4. Set binary to False to see \n",
    "ThirdSent = TaggedSents[2]\n",
    "NeThird = nltk.ne_chunk(ThirdSent)\n",
    "print(\"-----3RD SENTENCE, BINARY = False-----\",'\\n',NeThird)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}