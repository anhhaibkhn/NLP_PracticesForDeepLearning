{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package tagsets to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package tagsets is already up-to-date!\n"
    },
    {
     "data": {
      "text/plain": "[('I', 'PRP'),\n ('enjoy', 'VBP'),\n ('playing', 'VBG'),\n ('sports', 'NNS'),\n ('like', 'IN'),\n ('badminton', 'NN')]"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercis 10: Performing Rule-Based POS Tagging\n",
    "# 1: import nltk and punkt\n",
    "# NLTK has trainied POS tagger \n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "# 2: Store an input string in a variable named s\n",
    "s = 'I enjoy playing sports like badminton'\n",
    "# 3:Tokenize the sentence\n",
    "tokens = nltk.word_tokenize(s)\n",
    "# 4: Apply the POS tagger on the tokens and then print the tagset\n",
    "tags = nltk.pos_tag(tokens)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "PRP: pronoun, personal\n    hers herself him himself hisself it itself me myself one oneself ours\n    ourselves ownself self she thee theirs them themselves they thou thy us\nVBP: verb, present tense, not 3rd person singular\n    predominate wrap resort sue twist spill cure lengthen brush terminate\n    appear tend stray glisten obtain comprise detest tease attract\n    emphasize mold postpone sever return wag ...\nVBG: verb, present participle or gerund\n    telegraphing stirring focusing angering judging stalling lactating\n    hankerin' alleging veering capping approaching traveling besieging\n    encrypting interrupting erasing wincing ...\nNN: noun, common, singular or mass\n    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n    investment slide humour falloff slick wind hyena override subhumanity\n    machinist ...\n"
    }
   ],
   "source": [
    "# 5: To understand \"NN\" POS tag stands for\n",
    "nltk.help.upenn_tagset(\"PRP\")\n",
    "nltk.help.upenn_tagset(\"VBP\")\n",
    "nltk.help.upenn_tagset(\"VBG\")\n",
    "nltk.help.upenn_tagset(\"NN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('but', 'CC'),\n ('I', 'PRP'),\n ('mentioned', 'VBD'),\n ('that', 'IN'),\n ('Im', 'NNP'),\n ('going', 'VBG'),\n ('to', 'TO'),\n ('play', 'VB'),\n ('fun', 'JJ'),\n ('badmiton', 'NN'),\n ('for', 'IN'),\n ('the', 'DT'),\n ('play', 'NN'),\n ('on', 'IN'),\n ('this', 'DT'),\n ('Wed', 'NNP')]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check a sentence with hommonyms and see it tagset\n",
    "sentence2 = 'but I mentioned that Im going to play fun badmiton for the play on this Wed'\n",
    "tag2 = nltk.pos_tag(nltk.word_tokenize(sentence2))\n",
    "tag2\n",
    "# This show that POS taggers can differentiate between homonyms like Play(VerB) and play(NouN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "but ---> CCONJ ---> CC ---> conjunction, coordinating\nI ---> PRON ---> PRP ---> pronoun, personal\nmentioned ---> VERB ---> VBD ---> verb, past tense\nthat ---> SCONJ ---> IN ---> conjunction, subordinating or preposition\nI ---> PRON ---> PRP ---> pronoun, personal\nam ---> AUX ---> VBP ---> verb, non-3rd person singular present\ngoing ---> VERB ---> VBG ---> verb, gerund or present participle\nto ---> PART ---> TO ---> infinitival \"to\"\nplay ---> VERB ---> VB ---> verb, base form\nbadmiton ---> NOUN ---> NN ---> noun, singular or mass\nfor ---> ADP ---> IN ---> conjunction, subordinating or preposition\nthe ---> DET ---> DT ---> determiner\nplay ---> NOUN ---> NN ---> noun, singular or mass\non ---> ADP ---> IN ---> conjunction, subordinating or preposition\nthis ---> DET ---> DT ---> determiner\nWednesday ---> PROPN ---> NNP ---> noun, proper singular\n"
    }
   ],
   "source": [
    "# Exercise 11: Performing Stochastic POS tagging. spacy's POS tagger is a stochastic one.\n",
    "import spacy\n",
    "# load spaCy7's en\\core_web_sm model for English \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Fit the model on the sentence we want to assign POS tags to. \n",
    "doc = nlp(u\"but I mentioned that I am going to play badmiton for the play on this Wednesday\")\n",
    "# Tokenize the sentence, assign POS tags and print them\n",
    "    # print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "    #         token.shape_, token.is_alpha, token.is_stop)\n",
    "for token in doc: \n",
    "    print(token.text, \"--->\", token.pos_, \"--->\", token.tag_, \"--->\", spacy.explain(token.tag_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'verb, modal auxiliary'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to understand the tag ,\"VBD\",\"NN\",\"PRP\"\n",
    "spacy.explain(\"VBZ\")\n",
    "spacy.explain(\"MD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package tagsets to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package tagsets is already up-to-date!\n"
    }
   ],
   "source": [
    "# FROM Exercis 10: Performing Rule-Based POS Tagging\n",
    "# 1: import nltk and punkt\n",
    "# NLTK has trainied POS tagger \n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "# 2: Store an input string in a variable named s\n",
    "s = 'I enjoy playing some fun sports like badminton'\n",
    "\n",
    "# 3:Tokenize the sentence\n",
    "tokens = nltk.word_tokenize(s)\n",
    "# 4: Apply the POS tagger on the tokens and then print the tagset\n",
    "tagset = nltk.pos_tag(tokens)\n",
    "tagset\n",
    "\n",
    "# Exercise 12: perform Chunking with NLTK \n",
    "# 1 create a regular epression that will search for a noun phrase\n",
    "rule = r\"\"\"Noun Phrase: {(<DT>?<JJ>*<NN>?<NN>)|(<DT>?<JJ>*<NNS>)|<NN>}\"\"\"\n",
    "# look for <DT> determiner (ex: the) or <JJ> Adjective(ex: fun), then a single Noun\n",
    "# 2.Create an instance o RegxpParser and feed it the rule\n",
    "chunkParser = nltk.RegexpParser(rule)\n",
    "#3. Give chunkParser the tagset containing the tokens with their respective POS tags so that it can \n",
    "# perform chunking , and then draw the chunks:\n",
    "# chunked = chunkParser.parse(tagset)\n",
    "# chunked.draw()\n",
    "#4. different sentence\n",
    "a = \"The beautiful lady jumped on the sport car and he drove away into the high way\"\n",
    "tagset2 = nltk.pos_tag(nltk.word_tokenize(a))\n",
    "chunkParser2 = chunkParser.parse(tagset2)\n",
    "chunkParser2.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The beautiful lady lady nsubj\nthe sport car car pobj\nhe he nsubj\nthe high way way pobj\n"
    }
   ],
   "source": [
    "#Exercise 13: Perform Chunking with spaCy (spaCy is Supposed to be easier than NLTK)\n",
    "import spacy\n",
    "# load spaCy7's en\\core_web_sm model for English \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Fit the model on the sentence we want to assign POS tags to. \n",
    "doc = nlp(u\"The beautiful lady jumped on the sport car and he drove away into the high way\")\n",
    "#  Apply noun_chunks on this model, and for each chunk, print the text of the chunk\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_)\n",
    "# for token in doc.noun_chunks:\n",
    "#     # print(token.text)\n",
    "#     print(token.root.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package tagsets to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package tagsets is already up-to-date!\n"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "s2 = \"The beautiful lady jumped on the sport car and he drove away into the high way\"\n",
    "chink_tagset = nltk.pos_tag(nltk.word_tokenize(s2))\n",
    "\n",
    "# Exercise 14. Performing Chinking \n",
    "#1. Create rule that chunks the entire corpus and only creates chinks out of the words or phrases tagged as nouns or noun phrases:\n",
    "rule = r\"\"\"Chink: {<.*>+}\n",
    "}<VB.?|CC|RB|JJ|IN|DT|T0>+{\"\"\"\n",
    "# This regular expression is telling machine to ignore all words that are not Nouns or noun phrases(only extract N, N phrase as a chink)\n",
    "\n",
    "#2. Create an instance of RegexpParser and feed it the rule\n",
    "chinkParser = nltk.RegexpParser(rule)\n",
    "#3. Give ChinkParser the tagset and perform chinking \n",
    "chinked = chinkParser.parse(chink_tagset)\n",
    "chinked.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package treebank to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package treebank is already up-to-date!\n[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\nTagged sentences:  3914\nTagged words: 100676\nTraining completed\nAccuracy: 0.8939820022497188\n"
    }
   ],
   "source": [
    "# Activity 2: Build and Train POS Tagger* (Can I train my own tagger for CODE ?)\n",
    "\n",
    "#1. Pick a corpus to train (using nltk treebank corpus)\n",
    "import nltk \n",
    "import re\n",
    "import pprint \n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "nltk.download('treebank')\n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))\n",
    "# [(u'Pierre', u'NNP'), (u'Vinken', u'NNP'), (u',', u','), (u'61', u'CD'), (u'years', u'NNS'), (u'old', u'JJ'), (u',', u','), (u'will', u'MD'), (u'join', u'VB'), (u'the', u'DT'), (u'board', u'NN'), (u'as', u'IN'), (u'a', u'DT'), (u'nonexecutive', u'JJ'), (u'director', u'NN'), (u'Nov.', u'NNP'), (u'29', u'CD'), (u'.', u'.')]\n",
    "# Tagged sentences:  3914\n",
    "# Tagged words: 100676\n",
    "\n",
    "#2. Determine what are the feature the TAGGER will consder to assgin a tag to a word\n",
    "\"\"\"Before starting training a classifier, we must agree first on what features to use. Most obvious choices are: the word itself, the word before and the word after. That’s a good start, but we can do so much better. For example, the 2-letter suffix is a great indicator of past-tense verbs, ending in “-ed”. 3-letter suffix helps recognize the present participle ending in “-ing” \"\"\"\n",
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return  {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }\n",
    "\n",
    "# pprint.pprint(features(['This', 'is', 'a', 'sentence'], 2))\n",
    "# {'capitals_inside': False,\n",
    "#  'has_hyphen': False,\n",
    "#  'is_all_caps': False,\n",
    "#  'is_all_lower': True,\n",
    "#  'is_capitalized': False,\n",
    "#  'is_first': False,\n",
    "#  'is_last': False,\n",
    "#  'is_numeric': False,\n",
    "#  'next_word': 'sentence',\n",
    "#  'prefix-1': 'a',\n",
    "#  'prefix-2': 'a',\n",
    "#  'prefix-3': 'a',\n",
    "#  'prev_word': 'is',\n",
    "#  'suffix-1': 'a',\n",
    "#  'suffix-2': 'a',\n",
    "#  'suffix-3': 'a',\n",
    "#  'word': 'a'}\n",
    "\n",
    "#3. Create a fucntion to strip the tagged words of their tags, then feed them to the TAGGER\n",
    "\"\"\"Remove the tag for each tagged term.\n",
    "    :param tagged_sentence: a POS tagged sentence\n",
    "    :type tagged_sentence: list\n",
    "    :return: a list of tags\n",
    "    :rtype: list of strings\"\"\"\n",
    "def untag(tagged_sentence):\n",
    "    return [w for w, t in tagged_sentence] #?team\n",
    "\n",
    "# S_test = ((u'Pierre', u'NNP'), (u'Vinken', u'NNP'), (u',', u','), (u'61', u'CD'), (u'years', u'NNS'), (u'old', u'JJ'), (u',', u','), (u'will', u'MD'), (u'join', u'VB'), (u'the', u'DT'), (u'board', u'NN'), (u'as', u'IN'), (u'a', u'DT'), (u'nonexecutive', u'JJ'), (u'director', u'NN'), (u'Nov.', u'NNP'), (u'29', u'CD'), (u'.', u'.'),(u'Pierre', u'NNP'), (u'Vinken', u'NNP'), (u',', u','), (u'61', u'CD'), (u'years', u'NNS'), (u'old', u'JJ'), (u',', u','), (u'will', u'MD'), (u'join', u'VB'), (u'the', u'DT'), (u'board', u'NN'), (u'as', u'IN'), (u'a', u'DT'), (u'nonexecutive', u'JJ'), (u'director', u'NN'), (u'Nov.', u'NNP'), (u'29', u'CD'), (u'.', u'.'))\n",
    "\n",
    "# untag(S_test)\n",
    "\n",
    "# #4. Build a dataset and split into Training and Test data sets, Assign features(X), POS tags(Y)\n",
    "# \"\"\" Split the dataset for training and testing\"\"\"\n",
    "cutoff = int(.75 * len(tagged_sentences))\n",
    "training_sentences = tagged_sentences[:cutoff]\n",
    "test_sentences = tagged_sentences[cutoff:]\n",
    "\n",
    "# print(len(training_sentences))\n",
    "# print(len(test_sentences))\n",
    "\n",
    "def TransformToDataSet(tagged_sentences):\n",
    "    X, y = [], []\n",
    " \n",
    "    for tagged in tagged_sentences:\n",
    "        for index in range(len(tagged)):\n",
    "            X.append(features(untag(tagged), index))\n",
    "            y.append(tagged[index][1])\n",
    " \n",
    "    return X, y\n",
    "\n",
    "# # Get X,Y \n",
    "X_train, y_train = TransformToDataSet(training_sentences)\n",
    "\n",
    "#5. Use Decision Tree classifier to train the tagger. \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "clf = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='entropy'))\n",
    "])\n",
    " \n",
    "clf.fit(X_train[:10000], y_train[:10000])   # Use only the first 10K samples if you're running it multiple times. It takes a fair bit :)\n",
    " \n",
    "print('Training completed')\n",
    "\n",
    "X_test, Y_test = TransformToDataSet(test_sentences)\n",
    " \n",
    "print(\"Accuracy:\", clf.score(X_test, Y_test))\n",
    "# Accuracy expectation: 0.904186083882\n",
    "\n",
    "#6. Import the classifier, initialize it, fit the model on training and print the score. \n",
    "# def pos_tag(sentence):\n",
    "#     tags = clf.predict([features(sentence, index) for index in range(len(sentence))])\n",
    "#     print(sentence, tags)\n",
    "#     return zip(sentence, tags)\n",
    "\n",
    "# print(pos_tag(word_tokenize('This is my friend, John.')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[('This', 'DT'), ('is', 'VBZ'), ('my', 'NN'), ('friend', 'NN'), (',', ','), ('John', 'NNP'), ('.', '.')]\n"
    },
    {
     "data": {
      "text/plain": "[('This', 'DT'),\n ('is', 'VBZ'),\n ('my', 'NN'),\n ('friend', 'NN'),\n (',', ','),\n ('John', 'NNP'),\n ('.', '.')]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#6. Import the classifier, initialize it, fit the model on training and print the score. \n",
    "def pos_tag(sentence):\n",
    "    tags = clf.predict([features(sentence, index) for index in range(len(sentence))])\n",
    "    # NewSentence = [\"', '\".join(item) for item in zip(sentence, tags)]   # 1st way\n",
    "    # tagged_sentence  = list(map(list, zip(sentence, tags)))             # 2nd way \n",
    "    PosTagSentence = list(zip(sentence, tags)) # Final way \n",
    "\n",
    "    # print(NewSentence)\n",
    "    # print(tagged_sentence)\n",
    "    print(PosTagSentence)\n",
    "    \n",
    "    return PosTagSentence\n",
    " \n",
    "pos_tag(word_tokenize('This is my friend, John.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[('Mr', 'NNP'), ('NguyenHai', 'NNP'), ('may', 'MD'), ('visit', 'VB'), ('the', 'DT'), ('Taj', 'NNP'), ('Mahal', 'NNP'), ('after', 'IN'), ('taking', 'VBG'), ('a', 'DT'), ('SpiceJet', 'NNP'), ('flight', 'NN'), ('from', 'IN'), ('Tokyo', 'NNP'), ('.', '.')]\n"
    }
   ],
   "source": [
    "# Exercise 15: Perform Named Entity Recognition with NLTK\n",
    "# using ne_chunk algorithm of NLTK \n",
    "import nltk  \n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words') \n",
    "\n",
    "# 1. Store an input sentence in a var\n",
    "SentenceEx  = \"Mr NguyenHai may visit the Taj Mahal after taking a SpiceJet flight from Tokyo.\"\n",
    "# 2. Tokenize the sentence and assign POS tags to the tokens\n",
    "TagSentenceEx = nltk.pos_tag(nltk.word_tokenize(SentenceEx))\n",
    "\n",
    "# 3. Apply ne_chunk, True: not classify Name Entities, False: classify with categories \n",
    "NeSentenceEx = nltk.ne_chunk(TagSentenceEx, binary = False)\n",
    "NeSentenceEx.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Nguyen ORG Companies, agencies, institutions, etc.\nthe Taj Mahal PRODUCT Objects, vehicles, foods, etc. (not services)\nSpiceJet ORG Companies, agencies, institutions, etc.\nTokyo GPE Countries, cities, states\nNguyen Ngoc Hai PERSON People, including fictional\nSpiceJet ORG Companies, agencies, institutions, etc.\nTokyo GPE Countries, cities, states\n"
    }
   ],
   "source": [
    "# Exercise 16: Perform Named Entity Recognition with spaCy,(spaCy has several NERs)\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#1. Fit spaCy 's English model on the example sentence \n",
    "spaCyEx  = nlp(u\"Nguyen may visit the Taj Mahal after taking a SpiceJet flight from Tokyo.\")\n",
    "#2. For each entity in the sentence, print the text of entity and label\n",
    "for ent in spaCyEx.ents:\n",
    "    print(ent.text, ent.label_, spacy.explain(ent.label_))\n",
    "\n",
    "#3. Fit spaCy 's English model on the NEW example sentence     \n",
    "spaCyEx2  = nlp(u\"Nguyen Ngoc Hai visited the Taj Mahal after taking a SpiceJet flight from Tokyo.\")\n",
    "#4. repeat step 2\n",
    "for ent in spaCyEx2.ents:\n",
    "    print(ent.text, ent.label_, spacy.explain(ent.label_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "olf', 'NE')\n\n ('Mr. Steinberg', 'NE')\n\n ('British Airways PLC', 'NE')\n\n ('Reliance', 'NE')\n\n ('UAL', 'NE')\n\n ('Reliance', 'NE')\n\n ('UAL', 'NE')\n\n ('UAL', 'NE')\n\n ('Market', 'NE')\n\n ('Reliance', 'NE')\n\n ('Coniston Partners', 'NE')\n\n ('New York', 'NE')\n\n ('UAL', 'NE')\n\n ('UAL', 'NE')\n\n ('Coniston', 'NE')\n\n ('UAL', 'NE')\n\n ('New York Stock Exchange', 'NE')\n\n ('UAL', 'NE')\n\n ('Reliance', 'NE')\n\n ('Reliance', 'NE')\n\n ('Mr. Steinberg', 'NE')\n\n ('Reliance', 'NE')\n\n ('UAL', 'NE')\n\n ('Mr. Steinberg', 'NE')\n\n ('UAL', 'NE')\n\n ('Mr. Wolf', 'NE')\n\n ('Mr. Wolf', 'NE')\n\n ('Tiger International Inc', 'NE')\n\n ('Mr. Wolf', 'NE')\n\n ('UAL', 'NE')\n\n ('Primerica Corp.', 'NE')\n\n ('New York', 'NE')\n\n ('Williams', 'NE')\n\n ('Primerica', 'NE')\n\n ('Williams', 'NE')\n\n ('Williams', 'NE')\n\n ('Williams', 'NE')\n\n ('Williams', 'NE')\n\n ('New York Stock Exchange', 'NE')\n\n ('Primerica', 'NE')\n\n ('Williams', 'NE')\n\n ('Duluth', 'NE')\n\n ('Primerica', 'NE')\n\n ('Intelogic Trace Inc.', 'NE')\n\n ('San Antonio', 'NE')\n\n ('Texas', 'NE')\n\n ('Intelogic', 'NE')\n\n ('Martin Ackerman', 'NE')\n\n ('Mr. Ackerman', 'NE')\n\n ('Mr. Edelman', 'NE')\n\n ('Datapoint Corp.', 'NE')\n\n ('New York Stock Exchange', 'NE')\n\n ('Intelogic', 'NE')\n\n ('Mr. Edelman', 'NE')\n\n ('Marty Ackerman', 'NE')\n\n ('Mr. Ackerman', 'NE')\n\n ('Mr. Edelman', 'NE')\n\n ('Dow Jones', 'NE')\n\n ('Telerate', 'NE')\n\n ('EST', 'NE')\n\n ('Telerate', 'NE')\n\n ('Dow Jones', 'NE')\n\n ('Dow Jones', 'NE')\n\n ('Telerate', 'NE')\n\n ('Telerate', 'NE')\n\n ('New York Stock Exchange', 'NE')\n\n ('Telerate', 'NE')\n\n ('Telerate', 'NE')\n\n ('Dow Jones', 'NE')\n\n ('Barron', 'NE')\n\n ('Rockwell International Corp.', 'NE')\n\n ('Donald Beall', 'NE')\n\n ('Rockwell', 'NE')\n\n ('Rockwell', 'NE')\n\n ('Sales', 'NE')\n\n ('Mr. Beall', 'NE')\n\n ('Rockwell', 'NE')\n\n ('Colorliner', 'NE')\n\n ('Aerospace', 'NE')\n\n ('Dell Computer Corp.', 'NE')\n\n ('Austin', 'NE')\n\n ('Intel', 'NE')\n\n ('Dell', 'NE')\n\n ('World', 'NE')\n\n ('Brazil', 'NE')\n\n ('Mexico', 'NE')\n\n ('Brazilian', 'NE')\n\n ('Brazilian', 'NE')\n\n ('Arthur Stevenson', 'NE')\n\n ('New York', 'NE')\n\n ('Brazil', 'NE')\n\n ('Brazil', 'NE')\n\n ('Brazil', 'NE')\n\n ('Shearson Lehman Hutton', 'NE')\n\n ('New York', 'NE')\n\n ('Ganes', 'NE')\n\n ('Brazil', 'NE')\n\n ('Brazilian', 'NE')\n\n ('Thomas Oxnard', 'NE')\n\n ('Hackensack', 'NE')\n\n ('Brazil', 'NE')\n\n ('Mr. Oxnard', 'NE')\n\n ('Brazilian', 'NE')\n\n ('Mr. Oxnard', 'NE')\n\n ('Brazil', 'NE')\n\n ('Brazil', 'NE')\n\n ('Oxnard', 'NE')\n\n ('Mexico', 'NE')\n\n ('ENERGY', 'NE')\n\n ('Petroleum', 'NE')\n\n ('New York Mercantile Exchange', 'NE')\n\n ('Gasoline', 'NE')\n\n ('West Texas', 'NE')\n\n ('U.S.', 'NE')\n\n ('American Petroleum Institute', 'NE')\n\n ('GRAINS', 'NE')\n\n ('AND', 'NE')\n\n ('Trading', 'NE')\n\n ('All Saints', 'NE')\n\n ('Europe', 'NE')\n\n ('U.S.', 'NE')\n\n ('Chinese', 'NE')\n\n ('U.S.', 'NE')\n\n ('Britain', 'NE')\n\n ('Traders', 'NE')\n\n ('Soviet Union', 'NE')\n\n ('U.S.', 'NE')\n\n ('Soviets', 'NE')\n\n ('COPPER', 'NE')\n\n ('Chilean', 'NE')\n\n ('Disputado', 'NE')\n\n ('Exxon Corp.', 'NE')\n\n ('Reuter', 'NE')\n\n ('Bougainville Island', 'NE')\n\n ('Bougainville', 'NE')\n\n ('Bougainville', 'NE')\n\n ('Younkers', 'NE')\n\n ('Midwestern', 'NE')\n\n ('Equitable', 'NE')\n\n ('Iowa Cos.', 'NE')\n\n ('Des Moines', 'NE')\n\n ('Equitable', 'NE')\n\n ('Iowa', 'NE')\n\n ('Nebraska', 'NE')\n\n ('Younkers', 'NE')\n\n ('Fred', 'NE')\n\n ('Equitable', 'NE')\n\n ('Younkers', 'NE')\n\n ('Tony Lama Co.', 'NE')\n\n ('Equus Investment', 'NE')\n\n ('Equus', 'NE')\n\n ('Equus Capital Corp.', 'NE')\n\n ('Houston', 'NE')\n\n ('Tony Lama', 'NE')\n\n ('Texas', 'NE')\n\n ('Western', 'NE')\n\n ('Tony Lama', 'NE')\n\n ('Tony Lama', 'NE')\n\n ('Tony Lama', 'NE')\n\n ('Reuters Holdings PLC', 'NE')\n\n ('Michael Reupke', 'NE')\n\n ('Mr. Reupke', 'NE')\n\n ('Reuters', 'NE')\n\n ('Mr. Reupke', 'NE')\n\n ('Mr. Reupke', 'NE')\n\n ('Mr. Reupke', 'NE')\n\n ('Reuters', 'NE')\n\n ('Mark Shepperd', 'NE')\n\n ('UBS Phillips', 'NE')\n\n ('London', 'NE')\n\n ('London', 'NE')\n\n ('Reuters', 'NE')\n\n ('U.S.', 'NE')\n\n ('American', 'NE')\n\n ('Reuters', 'NE')\n\n ('London', 'NE')\n\n ('Mr. Reupke', 'NE')\n\n ('Nigel Judah', 'NE')\n\n ('Peter Holland', 'NE')\n\n ('Patrick Mannix', 'NE')\n\n ('DD Acquisition Corp.', 'NE')\n\n ('Unicorp Canada Corp.', 'NE')\n\n ('Cara Operations Ltd.', 'NE')\n\n ('DD Acquisition', 'NE')\n\n ('Delaware', 'NE')\n\n ('Dunkin', 'NE')\n\n ('DD Acquisition', 'NE')\n\n ('DD Acquisition', 'NE')\n\n ('Randolph', 'NE')\n\n ('Mass', 'NE')\n\n ('Cara', 'NE')\n\n ('Unicorp', 'NE')\n\n ('Toronto', 'NE')\n\n ('Savin Corp.', 'NE')\n\n ('Stamford', 'NE')\n\n ('Revenue', 'NE')\n\n ('Savin', 'NE')\n\n ('Savin', 'NE')\n\n ('Hadson Corp.', 'NE')\n\n ('Oklahoma City', 'NE')\n\n ('Hadson', 'NE')\n\n ('Dow Jones Industrial Average', 'NE')\n\n ('Standard', 'NE')\n\n ('Poor', 'NE')\n\n ('Dow Jones Equity Market Index', 'NE')\n\n ('New York Stock Exchange Composite Index', 'NE')\n\n ('New York Stock Exchange', 'NE')\n\n ('Big Board', 'NE')\n\n ('Philip Puccio', 'NE')\n\n ('Uncertainty', 'NE')\n\n ('Mr. Puccio', 'NE')\n\n ('Trading', 'NE')\n\n ('Richard Eakle', 'NE')\n\n ('Eakle Associates', 'NE')\n\n ('Fair Haven', 'NE')\n\n ('Campbell Soup', 'NE')\n\n ('John', 'NE')\n\n ('McMillin', 'NE')\n\n ('Woolworth', 'NE')\n\n ('Avon Products', 'NE')\n\n ('Paramount Communications', 'NE')\n\n ('Ferro', 'NE')\n\n ('Upjohn', 'NE')\n\n ('AMR', 'NE')\n\n ('New York', 'NE')\n\n ('Donald Trump', 'NE')\n\n ('American Airlines', 'NE')\n\n ('Mr. Trump', 'NE')\n\n ('UAL', 'NE')\n\n ('Drexel Burnham Lambert', 'NE')\n\n ('Michael Derchin', 'NE')\n\n ('United Airlines', 'NE')\n\n ('Georgia Gulf', 'NE')\n\n ('NL Industries', 'NE')\n\n ('Dallas', 'NE')\n\n ('Harold Simmons', 'NE')\n\n ('NL', 'NE')\n\n ('Great Northern Nekoosa', 'NE')\n\n ('Big Board', 'NE')\n\n ('Mead', 'NE')\n\n ('Federal Paper Board', 'NE')\n\n ('Scott Paper', 'NE')\n\n ('International Paper', 'NE')\n\n ('Champion International', 'NE')\n\n ('Texaco', 'NE')\n\n ('Texaco', 'NE')\n\n ('Santa Fe Pacific', 'NE')\n\n ('Santa Fe', 'NE')\n\n ('GenCorp', 'NE')\n\n ('Allergan', 'NE')\n\n ('Food', 'NE')\n\n ('Drug Administration', 'NE')\n\n ('American Stock Exchange Market Value Index', 'NE')\n\n ('Volume', 'NE')\n\n ('Old Spaghetti Warehouse', 'NE')\n\n ('Nissan Motor Co.', 'NE')\n\n ('Japan', 'NE')\n\n ('Nissan', 'NE')\n\n ('Profit', 'NE')\n\n ('Sales', 'NE')\n\n ('Nissan', 'NE')\n\n ('Atsushi Muramatsu', 'NE')\n\n ('Nissan', 'NE')\n\n ('Heritage Media Corp.', 'NE')\n\n ('New York', 'NE')\n\n ('POP Radio', 'NE')\n\n ('Heritage', 'NE')\n\n ('POP', 'NE')\n\n ('Heritage', 'NE')\n\n ('POP', 'NE')\n\n ('Heritage', 'NE')\n\n ('New', 'NE')\n\n ('POP Radio', 'NE')\n\n ('Heritage', 'NE')\n\n ('GenCorp Inc.', 'NE')\n\n ('Fairlawn', 'NE')\n\n('Harry Millis', 'NE')\n\n ('McDonald', 'NE')\n\n ('Cleveland', 'NE')\n\n ('GenCorp', 'NE')\n\n ('Kansas', 'NE')\n\n ('GenCorp', 'NE')\n\n ('Aerojet Ordnance', 'NE')\n\n ('Transamerica Corp.', 'NE')\n\n ('San Francisco', 'NE')\n\n ('Transamerica', 'NE')\n\n ('Hurricane Hugo', 'NE')\n\n ('California', 'NE')\n\n ('RMS International Inc.', 'NE')\n\n ('Hasbrouk Heights', 'NE')\n\n ('RMS', 'NE')\n\n ('RMS', 'NE')\n\n ('Sales', 'NE')\n\n ('Sales', 'NE')\n\n ('Meridian National Corp.', 'NE')\n\n ('McAlpine', 'NE')\n\n ('Meridian', 'NE')\n\n ('McAlpine', 'NE')\n\n ('Meridian National', 'NE')\n\n ('Meridian', 'NE')\n\n ('McAlpine', 'NE')\n\n ('McAlpine', 'NE')\n\n ('Meridian', 'NE')\n\n ('Haden', 'NE')\n\n ('MacLellan Holding', 'NE')\n\n ('Surrey', 'NE')\n\n ('England', 'NE')\n\n ('Meridian', 'NE')\n\n ('William Feniger', 'NE')\n\n ('Toledo', 'NE')\n\n ('Meridian', 'NE')\n\n ('Ratners Group PLC', 'NE')\n\n ('Weisfield', 'NE')\n\n ('Ratners', 'NE')\n\n ('Ratners', 'NE')\n\n ('Gerald Ratner', 'NE')\n\n ('Ratners', 'NE')\n\n ('London', 'NE')\n\n ('Ratners', 'NE')\n\n ('Weisfield', 'NE')\n\n ('Weisfield', 'NE')\n\n ('Ratners', 'NE')\n\n ('U.S.', 'NE')\n\n ('Ratners', 'NE')\n\n ('U.S.', 'NE')\n\n ('Carnival Cruise Lines Inc.', 'NE')\n\n ('Finland', 'NE')\n\n ('Carnival', 'NE')\n\n ('Waertsilae Marine Industries', 'NE')\n\n ('Finnish', 'NE')\n\n ('Carnival', 'NE')\n\n ('Carnival', 'NE')\n\n ('Finland', 'NE')\n\n ('Waertsilae', 'NE')\n\n ('Carnival', 'NE')\n\n ('Carnival', 'NE')\n\n ('Fantasy', 'NE')\n\n ('Carnival', 'NE')\n\n ('Finnish', 'NE')\n\n ('Carnival', 'NE')\n\n ('Valley Federal Savings', 'NE')\n\n ('Loan Association', 'NE')\n\n ('Van Nuys', 'NE')\n\n ('Valley Federal', 'NE')\n\n ('Valley Federal', 'NE')\n\n ('America Bank Corp.', 'NE')\n\n ('Midwest Financial Group Inc.', 'NE')\n\n ('America', 'NE')\n\n ('Peoria', 'NE')\n\n ('Midwest Financial', 'NE')\n\n ('Midwest Financial', 'NE')\n\n ('America', 'NE')\n\n ('Kalamazoo', 'NE')\n\n ('America', 'NE')\n\n ('Midwest Financial', 'NE')\n\n ('America', 'NE')\n\n ('America', 'NE')\n\n ('America', 'NE')\n\n ('Coleco Industries Inc.', 'NE')\n\n ('Ranger Industries Inc', 'NE')\n\n ('Avon', 'NE')\n\n ('Coleco', 'NE')\n\n ('Cabbage Patch', 'NE')\n\n ('Coleco', 'NE')\n\n ('New York', 'NE')\n\n ('ORTEGA', 'NE')\n\n ('Nicaraguan', 'NE')\n\n ('Bush', 'NE')\n\n ('Ortega', 'NE')\n\n ('U.S.', 'NE')\n\n ('U.S.', 'NE')\n\n ('White House', 'NE')\n\n ('Contra', 'NE')\n\n ('Honduras', 'NE')\n\n ('East German', 'NE')\n\n ('Krenz', 'NE')\n\n ('Communist Party', 'NE')\n\n ('Moscow', 'NE')\n\n ('Soviet', 'NE')\n\n ('Gorbachev', 'NE')\n\n ('East Germans', 'NE')\n\n ('Czechoslovakia', 'NE')\n\n ('East Berlin', 'NE')\n\n ('West Germany', 'NE')\n\n ('Communist', 'NE')\n\n ('Berlin Wall', 'NE')\n\n ('Health', 'NE')\n\n ('Alzheimer', 'NE')\n\n ('Michigan', 'NE')\n\n ('Bush', 'NE')\n\n ('Democrat', 'NE')\n\n ('Poland', 'NE')\n\n ('South Africa', 'NE')\n\n ('Namibian', 'NE')\n\n ('Angola', 'NE')\n\n ('South African', 'NE')\n\n ('Guerrilla', 'NE')\n\n ('Namibia', 'NE')\n\n ('Lebanon', 'NE')\n\n ('Saudi Arabian', 'NE')\n\n ('Islamic Jihad', 'NE')\n\n ('Riyadh', 'NE')\n\n ('Beirut', 'NE')\n\n ('Moslem', 'NE')\n\n ('U.S.', 'NE')\n\n ('Nixon', 'NE')\n\n ('Chinese', 'NE')\n\n ('Beijing', 'NE')\n\n ('China', 'NE')\n\n ('Beijing', 'NE')\n\n ('U.S.', 'NE')\n\n ('China', 'NE')\n\n ('Mexico', 'NE')\n\n ('Salinas', 'NE')\n\n ('Salinas', 'NE')\n\n ('Pakistan', 'NE')\n\n ('Bhutto', 'NE')\n\n ('Islamabad', 'NE')\n\n ('White House', 'NE')\n\n ('Bush', 'NE')\n\n ('Soviet', 'NE')\n\n ('Gorbachev', 'NE')\n\n ('Malta', 'NE')\n\n ('U.S.', 'NE')\n\n ('Bush', 'NE')\n\n ('Andean', 'NE')\n\n ('South America', 'NE')\n\n ('Pan', 'NE')\n\n ('CIA', 'NE')\n\n ('FBI', 'NE')\n\n ('Scotland', 'NE')\n\n ('Israel', 'NE')\n\n ('West Germany', 'NE')\n\n ('U.S.', 'NE')\n\n ('James', 'NE')\n\n ('Mutual Life Insurance', 'NE')\n\n ('New York', 'NE')\n\n ('New York City', 'NE')\n\n ('Sony Corp.', 'NE')\n\n ('Columbia Pictures Entertainment Inc.', 'NE')\n\n ('Columbia', 'NE')\n\n ('Sony Columbia Acquisition Corp.', 'NE')\n\n ('Columbia', 'NE')\n\n ('Sony', 'NE')\n\n ('Sony', 'NE')\n\n ('Jon Peters', 'NE')\n\n ('Peter Guber', 'NE')\n\n ('Sony', 'NE')\n\n ('Warner Communications Inc.', 'NE')\n\n ('Warner', 'NE')\n\n ('Xerox Corp.', 'NE')\n\n ('Crum', 'NE')\n\n ('Forster', 'NE')\n\n ('Xerox', 'NE')\n\n ('Xerox', 'NE')\n\n ('Crum', 'NE')\n\n ('Hurricane Hugo', 'NE')\n\n ('Hurricane Hugo', 'NE')\n\n ('California', 'NE')\n\n ('Komatsu', 'NE')\n\n ('Sales', 'NE')\n\n ('Brisk', 'NE')\n\n ('Domestic', 'NE')\n\n ('Demand', 'NE')\n\n ('Europe', 'NE')\n\n ('Southeast Asia', 'NE')\n\n ('Komatsu', 'NE')\n\n ('Net', 'NE')\n\n ('ECONOMIC', 'NE')\n\n ('GROWTH', 'NE')\n\n ('Factory', 'NE')\n\n ('Campbell Soup', 'NE')\n\n ('McGovern', 'NE')\n\n ('Dorrance', 'NE')\n\n ('Campbell', 'NE')\n\n ('Chicago Merc', 'NE')\n\n ('Big Board', 'NE')\n\n ('Phelan', 'NE')\n\n ('Georgia Gulf', 'NE')\n\n ('Harold Simmons', 'NE')\n\n ('NL Industries', 'NE')\n\n ('Congress', 'NE')\n\n ('Bush', 'NE')\n\n ('House', 'NE')\n\n ('Senate', 'NE')\n\n ('Steinberg', 'NE')\n\n ('United Air', 'NE')\n\n ('Takeover', 'NE')\n\n ('House', 'NE')\n\n ('Transportation Department', 'NE')\n\n ('USX', 'NE')\n\n ('OSHA', 'NE')\n\n ('Random House', 'NE')\n\n ('Robert Bernstein', 'NE')\n\n ('Cray Research', 'NE')\n\n ('Seymour Cray', 'NE')\n\n ('Light', 'NE')\n\n ('Transportation Department', 'NE')\n\n ('Treasury', 'NE')\n\n ('Congress', 'NE')\n\n ('U.S.', 'NE')\n\n ('Congress', 'NE')\n\n ('Dow Jones', 'NE')\n\n ('Shearson Lehman Hutton Treasury', 'NE')\n\n ('Dollar', 'NE')\n\n ('Exchange Commission', 'NE')\n\n ('Drexel Burnham Lambert', 'NE')\n\n ('Columbia Savings', 'NE')\n\n ('Loan Association', 'NE')\n\n ('Thomas Spiegel', 'NE')\n\n ('Columbia', 'NE')\n\n ('Mr. Spiegel', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('Mr. Spiegel', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('Mr. Spiegel', 'NE')\n\n ('Columbia', 'NE')\n\n ('Southern California', 'NE')\n\n ('Columbia', 'NE')\n\n ('Spiegel', 'NE')\n\n ('Carl Lindner', 'NE')\n\n ('American Financial', 'NE')\n\n ('Irwin Jacobs', 'NE')\n\n ('Pacific Financial Research', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('Drexel', 'NE')\n\n ('Allied Stores', 'NE')\n\n ('Western Union Telegraph', 'NE')\n\n ('Gillett Holdings', 'NE')\n\n ('SCI Television', 'NE')\n\n ('Texas Air', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('Mellon Bank', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('Columbia', 'NE')\n\n ('California', 'NE')\n\n ('Columbia', 'NE')\n\n ('Mr. Spiegel', 'NE')\n\n ('Columbia', 'NE')\n\n ('Lewis Ranieri', 'NE')\n\n ('Ranieri Associates', 'NE')\n\n ('New York', 'NE')\n\n ('Mr. Spiegel', 'NE')\n\n ('Wall Street', 'NE')\n\n ('Columbia', 'NE')\n\n ('Jonathan Gray', 'NE')\n\n ('Sanford', 'NE')\n\n ('Columbia', 'NE')\n\n ('Mr. Spiegel', 'NE')\n\n ('Pauline Yoshihashi', 'NE')\n\n ('Los Angeles', 'NE')\n\n ('Columbia Savings', 'NE')\n\n ('NYSE', 'NE')\n\n ('Business', 'NE')\n\n ('Year', 'NE')\n\n ('Average', 'NE')\n\n ('Common', 'NE')\n\n ('Genetics Institute Inc.', 'NE')\n\n ('Cambridge', 'NE')\n\n ('U.S.', 'NE')\n\n ('DNA', 'NE')\n\n ('Sandoz', 'NE')\n\n ('Genetics Institute', 'NE')\n\n ('Genetics Institute', 'NE')\n\n ('Genetics Institute', 'NE')\n\n ('BMP', 'NE')\n\n ('Bush', 'NE')\n\n ('Clarence Thomas', 'NE')\n\n ('American Bar Association', 'NE')\n\n ('Mr. Thomas', 'NE')\n\n ('Senate', 'NE')\n\n ('ABA', 'NE')\n\n ('Mr. Thomas', 'NE')\n\n ('Equal Employment Opportunity Commission', 'NE')\n\n ('House', 'NE')\n\n ('EEOC', 'NE')\n\n ('Mr. Thomas', 'NE')\n\n ('ABA', 'NE')\n\n ('ABA', 'NE')\n\n ('David Runkel', 'NE')\n\n ('ABA', 'NE')\n\n ('Metallgesellschaft AG', 'NE')\n\n ('Lentjes AG', 'NE')\n\n ('Ferdinand Lentjes Foundation', 'NE')\n\n ('Metallgesellschaft', 'NE')\n\n ('West', 'NE')\n\n ('Lentjes', 'NE')\n\n ('Lurgi', 'NE')\n\n ('Lentjes', 'NE')\n\n ('Lentjes', 'NE')\n\n ('Frankfurt', 'NE')\n\n ('U.S. International Trade Commission', 'NE')\n\n ('U.S.', 'NE')\n\n ('Hong Kong', 'NE')\n\n ('Taiwan', 'NE')\n\n ('South Korea', 'NE')\n\n ('Commerce Department', 'NE')\n\n ('U.S.', 'NE')\n\n ('U.S.', 'NE')\n\n ('U.S.', 'NE')\n\n ('ITC', 'NE')\n\n ('Commerce Department', 'NE')\n\n ('ITC', 'NE')\n\n ('U.S.', 'NE')\n\n ('U.S.', 'NE')\n\n ('Taiwan', 'NE')\n\n ('South Korea', 'NE')\n\n ('Hong Kong', 'NE')\n\n ('ITC', 'NE')\n\n ('ITC', 'NE')\n\n ('Wilmington', 'NE')\n\n ('France', 'NE')\n\n ('West Germany', 'NE')\n\n ('Upjohn Co.', 'NE')\n\n ('Upjohn', 'NE')\n\n ('Upjohn', 'NE')\n\n ('Upjohn', 'NE')\n\n ('Chairman Theodore Cooper', 'NE')\n\n ('Jonathan', 'NE')\n\n ('Wertheim Schroder', 'NE')\n\n ('Upjohn', 'NE')\n\n ('Upjohn', 'NE')\n\n ('Upjohn', 'NE')\n\n ('New York Stock Exchange', 'NE')\n\n ('Upjohn', 'NE')\n\n ('Upjohn', 'NE')\n\n ('Jerry Chapman', 'NE')\n\n ('WayMar Associates', 'NE')\n\n ('Henry Holt', 'NE')\n\n ('Wedtech', 'NE')\n\n ('William Sternberg', 'NE')\n\n ('Bronx', 'NE')\n\n ('Wedtech', 'NE')\n\n ('Washington', 'NE')\n\n ('Wedtech', 'NE')\n\n ('Bribe', 'NE')\n\n ('Mr. Sternberg', 'NE')\n\n ('Matthew', 'NE')\n\n ('Wedtech', 'NE')\n\n ('Army', 'NE')\n\n ('Navy', 'NE')\n\n ('John Mariotta', 'NE')\n\n ('Fred Neuberger', 'NE')\n\n ('Wedtech', 'NE')\n\n ('Wedtech', 'NE')\n\n ('Mr. Neuberger', 'NE')\n\n ('Great Society', 'NE')\n\n ('Mr. Neuberger', 'NE')\n\n ('Italian', 'NE')\n\n ('Mr. Mariotta', 'NE')\n\n ('Puerto Rico', 'NE')\n\n ('Mariotta', 'NE')\n\n ('Wedtech', 'NE')\n\n ('South Bronx', 'NE')\n\n ('Jimmy Carter', 'NE')\n\n ('Carter', 'NE')\n\n ('South Bronx', 'NE')\n\n ('South Bronx', 'NE')\n\n ('Congressman Mario Biaggi', 'NE')\n\n ('Wedtech', 'NE')\n\n ('Reagan', 'NE')\n\n ('Wedtech', 'NE')\n\n ('Mr. Mariotta', 'NE')\n\n ('None', 'NE')\n\n ('Wedtech', 'NE')\n\n ('Rusty Kent London', 'NE')\n\n ('Wedtech', 'NE')\n\n ('HUD', 'NE')\n\n ('Wedtech', 'NE')\n\n ('U.S.', 'NE')\n\n ('East', 'NE')\n\n ('Wedtech', 'NE')\n\n ('Mr. Stern', 'NE')\n\n ('New York State Urban', 'NE')\n\n ('Finnish', 'NE')\n\n ('Waertsilae Marine Industries Oy', 'NE')\n\n ('Christian Andersson', 'NE')\n\n ('Waertsilae Marine', 'NE')\n\n ('Waertsilae Marine', 'NE')\n\n ('Waertsilae Marine', 'NE')\n\n ('Union Bank', 'NE')\n\n ('Finland', 'NE')\n\n ('Waertsilae Marine', 'NE')\n\n ('Waertsilae Marine', 'NE')\n\n ('Carnival Cruise Lines Inc', 'NE')\n\n ('Carnival', 'NE')\n\n ('Waertsilae Marine', 'NE')\n\n ('Waertsilae Marine', 'NE')\n\n ('Helsinki', 'NE')\n\n ('Comprehensive Care Corp.', 'NE')\n\n ('California', 'NE')\n\n ('Mr. Nichol', 'NE')\n\n ('Mr. Nichol', 'NE')\n\n ('Comprehensive Care', 'NE')\n\n ('Irvine', 'NE')\n\n ('St. Louis', 'NE')\n\n ('Mr. Karns', 'NE')\n\n ('Comprehensive Care', 'NE')\n\n ('Norfolk', 'NE')\n\n ('New York Stock Exchange', 'NE')\n\n ('Comprehensive Care', 'NE')\n\n ('Ralston Purina', 'NE')\n\n ('Ralston', 'NE')\n\n ('Ralston', 'NE')\n\n ('Greenville', 'NE')\n\n ('Hostess', 'NE')\n\n ('Cincinnati', 'NE')\n\n ('Ralston', 'NE')\n\n ('Continental Baking', 'NE')\n\n ('Ralston', 'NE')\n\n ('South America', 'NE')\n\n ('Ralston', 'NE')\n\n ('New York Stock Exchange', 'NE')\n\n ('First Chicago Corp.', 'NE')\n\n ('Ravenswood Financial Corp.', 'NE')\n\n ('Chicago', 'NE')\n\n ('Soviet Union', 'NE')\n\n ('U.S.', 'NE')\n\n ('Soviet', 'NE')\n\n ('Midwest', 'NE')\n\n ('Soviet', 'NE')\n\n ('River', 'NE')\n\n ('Railroad', 'NE')\n\n ('Soviets', 'NE')\n\n ('Soviet Union', 'NE')\n\n ('U.S.', 'NE')\n\n ('Soviet Union', 'NE')\n\n ('U.S.', 'NE')\n\n ('Soviet Union', 'NE')\n\n ('Mississippi River', 'NE')\n\n ('U.S.', 'NE')\n\n ('William Dunton', 'NE')\n\n ('U.S.', 'NE')\n\n ('Mississippi River', 'NE')\n\n ('St. Louis', 'NE')\n\n ('U.S. Army Corps', 'NE')\n\n ('Engineers', 'NE')\n\n ('Missouri River', 'NE')\n\n ('Mississippi River', 'NE')\n\n ('Army Corps', 'NE')\n\n ('Missouri River', 'NE')\n\n ('Barge', 'NE')\n\n ('Mississippi River', 'NE')\n\n ('Midwest', 'NE')\n\n ('Army Corps', 'NE')\n\n ('Engineers', 'NE')\n\n ('St. Louis', 'NE')\n\n ('Mississippi River', 'NE')\n\n ('Missouri River', 'NE')\n\n ('Army Corps', 'NE')\n\n ('Chicago Board', 'NE')\n\n ('Trade', 'NE')\n\n ('Board', 'NE')\n\n ('Trade', 'NE')\n\n ('Corn', 'NE')\n\n ('Soviet', 'NE')\n\n ('U.S.', 'NE')\n\n ('U.S.', 'NE')\n\n ('Iowa', 'NE')\n\n ('Chicago Central', 'NE')\n\n ('Pacific Railroad', 'NE')\n\n ('Waterloo', 'NE')\n\n ('Iowa', 'NE')\n\n ('U.S.', 'NE')\n\n ('Agriculture Department', 'NE')\n\n ('Bill Biedermann', 'NE')\n\n ('Allendale', 'NE')\n\n ('New Orleans', 'NE')\n\n ('Mississippi River', 'NE')\n\n ('Great Lakes', 'NE')\n\n ('Atlantic Coast', 'NE')\n\n ('New Orleans', 'NE')\n\n ('Indiana', 'NE')\n\n ('Baltimore', 'NE')\n\n ('Soviet Union', 'NE')\n\n ('Soviet', 'NE')\n\n ('Soviet Union', 'NE')\n\n ('U.S.', 'NE')\n\n ('ENERGY', 'NE')\n\n ('West', 'NE')\n\n ('German', 'NE')\n\n ('European', 'NE')\n\n ('Heating', 'NE')\n\n ('New York Mercantile Exchange', 'NE')\n\n ('West Texas Intermediate', 'NE')\n\n ('Gasoline', 'NE')\n\n ('PRECIOUS', 'NE')\n\n ('William', 'NE')\n\n ('Elders Futures', 'NE')\n\n ('New York', 'NE')\n\n ('Silver', 'NE')\n\n ('Silver', 'NE')\n\n ('Commodity Exchange', 'NE')\n\n ('COPPER', 'NE')\n\n ('Chilean', 'NE')\n\n ('Chile', 'NE')\n\n ('Los Bronces', 'NE')\n\n ('Minera Disputada', 'NE')\n\n ('Chicago', 'NE')\n\n ('Chicago', 'NE')\n\n ('Chicago', 'NE')\n\n ('National Association', 'NE')\n\n ('NCR Corp.', 'NE')\n\n ('Tower', 'NE')\n\n ('Novell Inc.', 'NE')\n\n ('NetWare', 'NE')\n\n ('USX Corp.', 'NE')\n\n ('USX', 'NE')\n\n ('Sales', 'NE')\n\n ('USX', 'NE')\n\n ('Peter Marcus', 'NE')\n\n ('PaineWebber Inc.', 'NE')\n\n ('USX', 'NE')\n\n ('USX', 'NE')\n\n ('Lorain', 'NE')\n\n ('Ohio', 'NE')\n\n ('Japan', 'NE')\n\n ('Kobe Steel Ltd', 'NE')\n\n ('Profit', 'NE')\n\n ('USX', 'NE')\n\n ('Inland Steel Industries Inc.', 'NE')\n\n ('New York Stock Exchange', 'NE')\n\n ('USX', 'NE')\n\n ('USX', 'NE')\n\n ('Charles Bradford', 'NE')\n\n ('Merrill Lynch Capital Markets', 'NE')\n\n ('USX', 'NE')\n\n ('Marathon Oil', 'NE')\n\n ('Texas Oil', 'NE')\n\n ('Gas', 'NE')\n\n ('USX', 'NE')\n\n ('TXO', 'NE')\n\n ('USX', 'NE')\n\n ('Carl Icahn', 'NE')\n\n ('USX', 'NE')\n\n ('Mr. Icahn', 'NE')\n\n ('Profit', 'NE')\n\n ('Sales', 'NE')\n\n ('John', 'NE')\n\n ('Leon J. Level', 'NE')\n\n ('Harvard University', 'NE')\n\n ('Graduate School', 'NE')\n\n ('Business', 'NE')\n\n ('David', 'NE')\n\n ('Delmont', 'NE')\n\n ('Bush', 'NE')\n\n ('Professors Philip Kurland', 'NE')\n\n ('University', 'NE')\n\n ('Chicago', 'NE')\n\n ('Laurence Tribe', 'NE')\n\n ('Harvard Law School', 'NE')\n\n ('Mr. Bush', 'NE')\n\n ('White House', 'NE')\n\n ('Mr. Tribe', 'NE')\n\n ('Kennedy', 'NE')\n\n ('Trinity Industries Inc.', 'NE')\n\n ('Trailer Train', 'NE')\n\n ('Chicago', 'NE')\n\n ('Trinity', 'NE')\n"
    }
   ],
   "source": [
    "# Activity 3: Performing NER on a tagged Corpus \n",
    "import nltk, re\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "nltk.download('treebank')\n",
    "\n",
    "#print(nltk.corpus.treebank.tagged_sents())\n",
    "TaggedSents = nltk.corpus.treebank.tagged_sents()\n",
    "\n",
    "for index in range(len(TaggedSents)):\n",
    "    FirstSentence = TaggedSents[index] # print(\"First Sentence\",'\\n',FirstSentence,'\\n')\n",
    "\n",
    "    NerFirst = nltk.ne_chunk(FirstSentence, binary = True)\n",
    "    # print('\\n',NerFirst)\n",
    "    # NerFirst.draw()\n",
    "    named_entities = []\n",
    "\n",
    "    for tagged_tree in NerFirst:\n",
    "        # print(tagged_tree)\n",
    "        if hasattr(tagged_tree, 'label'):\n",
    "            # print(\"-----ADD THIS TAGGED TREE-----\")\n",
    "            entity_name = ' '.join(child[0] for child in tagged_tree.leaves())\n",
    "            entity_type = tagged_tree.label()\n",
    "            named_entities.append((entity_name,entity_type))\n",
    "            # Stack.append(' '.join([child[0].lower() for child in tree]))\n",
    "            \n",
    "    #Specify any tag which is required 'GPE','PERSON', 'NE' is for binary = True \n",
    "    for tag in named_entities:\n",
    "        if tag[1]=='NE':  \n",
    "            print('\\n',tag)\n",
    "\n",
    "# MORE INFO: https://nlpforhackers.io/named-entity-extraction/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-----1ST SENTENCE, BINARY = TRUE----- \n (S\n  (NE Pierre/NNP Vinken/NNP)\n  ,/,\n  61/CD\n  years/NNS\n  old/JJ\n  ,/,\n  will/MD\n  join/VB\n  the/DT\n  board/NN\n  as/IN\n  a/DT\n  nonexecutive/JJ\n  director/NN\n  Nov./NNP\n  29/CD\n  ./.)\n-----2ND SENTENCE, BINARY = False----- \n (S\n  (PERSON Mr./NNP)\n  (PERSON Vinken/NNP)\n  is/VBZ\n  chairman/NN\n  of/IN\n  (ORGANIZATION Elsevier/NNP)\n  N.V./NNP\n  ,/,\n  the/DT\n  (GPE Dutch/NNP)\n  publishing/VBG\n  group/NN\n  ./.)\n-----3RD SENTENCE, BINARY = False----- \n (S\n  (PERSON Rudolph/NNP)\n  (GPE Agnew/NNP)\n  ,/,\n  55/CD\n  years/NNS\n  old/JJ\n  and/CC\n  former/JJ\n  chairman/NN\n  of/IN\n  (ORGANIZATION Consolidated/NNP Gold/NNP Fields/NNP)\n  PLC/NNP\n  ,/,\n  was/VBD\n  named/VBN\n  *-1/-NONE-\n  a/DT\n  nonexecutive/JJ\n  director/NN\n  of/IN\n  this/DT\n  (GPE British/JJ)\n  industrial/JJ\n  conglomerate/NN\n  ./.)\n[nltk_data] Downloading package treebank to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package treebank is already up-to-date!\n[nltk_data] Downloading package maxent_ne_chunker to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n[nltk_data] Downloading package words to\n[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package words is already up-to-date!\n"
    }
   ],
   "source": [
    "# Activity 3: Performing NER on a tagged Corpus (BOOK ANSWER)\n",
    "#1. Import necessary python packages\n",
    "import nltk, re\n",
    "nltk.download('treebank')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "#2. Print nltk.corpus.treebank.tagged_sents()\n",
    "TaggedSents = nltk.corpus.treebank.tagged_sents()\n",
    "FirstSent = TaggedSents[0]\n",
    "NeFirst = nltk.ne_chunk(FirstSent, binary=True)\n",
    "\n",
    "print(\"-----1ST SENTENCE, BINARY = TRUE-----\",'\\n',NeFirst)\n",
    "\n",
    "#3. Store 1st sentence to a var\n",
    "SecondSent = TaggedSents[1]\n",
    "NeSeconde = nltk.ne_chunk(SecondSent,binary=False)\n",
    "print(\"-----2ND SENTENCE, BINARY = False-----\",'\\n',NeSeconde)\n",
    "\n",
    "#4. Set binary to False to see \n",
    "ThirdSent = TaggedSents[2]\n",
    "NeThird = nltk.ne_chunk(ThirdSent)\n",
    "print(\"-----3RD SENTENCE, BINARY = False-----\",'\\n',NeThird)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}